{"created": 1745521482.9009798, "duration": 154.92940878868103, "exitcode": 1, "root": "/home/runner/work/llama-stack-tests/llama-stack-tests", "environment": {}, "summary": {"passed": 70, "failed": 6, "total": 76, "collected": 76}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py", "type": "Module"}]}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py", "outcome": "passed", "result": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-earth]", "type": "Function", "lineno": 96}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-saturn]", "type": "Function", "lineno": 96}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-mini-earth]", "type": "Function", "lineno": 96}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-mini-saturn]", "type": "Function", "lineno": 96}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-earth]", "type": "Function", "lineno": 115}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-saturn]", "type": "Function", "lineno": 115}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-mini-earth]", "type": "Function", "lineno": 115}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-mini-saturn]", "type": "Function", "lineno": 115}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-messages_missing]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-messages_role_invalid]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-tool_choice_invalid]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-tool_choice_no_tools]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-tools_type_invalid]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-messages_missing]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-messages_role_invalid]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tool_choice_invalid]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tool_choice_no_tools]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tools_type_invalid]", "type": "Function", "lineno": 139}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-messages_missing]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-messages_role_invalid]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_invalid]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_no_tools]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-tools_type_invalid]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-messages_missing]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-messages_role_invalid]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_invalid]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_no_tools]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-tools_type_invalid]", "type": "Function", "lineno": 160}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[openai/gpt-4o-case0]", "type": "Function", "lineno": 183}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 183}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[openai/gpt-4o-case0]", "type": "Function", "lineno": 202}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 202}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-calendar]", "type": "Function", "lineno": 226}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-math]", "type": "Function", "lineno": 226}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-mini-calendar]", "type": "Function", "lineno": 226}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-mini-math]", "type": "Function", "lineno": 226}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-calendar]", "type": "Function", "lineno": 249}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-math]", "type": "Function", "lineno": 249}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-mini-calendar]", "type": "Function", "lineno": 249}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-mini-math]", "type": "Function", "lineno": 249}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[openai/gpt-4o-case0]", "type": "Function", "lineno": 271}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 271}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[openai/gpt-4o-case0]", "type": "Function", "lineno": 295}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 295}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[openai/gpt-4o-case0]", "type": "Function", "lineno": 323}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 323}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[openai/gpt-4o-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[openai/gpt-4o-case0]", "type": "Function", "lineno": 374}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 374}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[openai/gpt-4o-case0]", "type": "Function", "lineno": 397}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[openai/gpt-4o-mini-case0]", "type": "Function", "lineno": 397}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-text_then_weather_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-weather_tool_then_text]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-add_product_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-get_then_create_event_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-compare_monthly_expense_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-text_then_weather_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-weather_tool_then_text]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-add_product_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-get_then_create_event_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-compare_monthly_expense_tool]", "type": "Function", "lineno": 425}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-text_then_weather_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-weather_tool_then_text]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-add_product_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-get_then_create_event_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-compare_monthly_expense_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-text_then_weather_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-weather_tool_then_text]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-add_product_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-get_then_create_event_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-compare_monthly_expense_tool]", "type": "Function", "lineno": 516}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-stream=False]", "type": "Function", "lineno": 599}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-stream=True]", "type": "Function", "lineno": 599}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-mini-stream=False]", "type": "Function", "lineno": 599}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-mini-stream=True]", "type": "Function", "lineno": 599}]}], "tests": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-earth]", "lineno": 96, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[openai/gpt-4o-earth]", "parametrize", "pytestmark", "openai/gpt-4o-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "earth"}, "setup": {"duration": 0.053512599999976374, "outcome": "passed"}, "call": {"duration": 0.5848815950002972, "outcome": "passed"}, "teardown": {"duration": 0.0003094280000368599, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-saturn]", "lineno": 96, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[openai/gpt-4o-saturn]", "parametrize", "pytestmark", "openai/gpt-4o-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "saturn"}, "setup": {"duration": 0.02292166699999143, "outcome": "passed"}, "call": {"duration": 1.5878716720003467, "outcome": "passed"}, "teardown": {"duration": 0.0003270709999014798, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-mini-earth]", "lineno": 96, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[openai/gpt-4o-mini-earth]", "parametrize", "pytestmark", "openai/gpt-4o-mini-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "earth"}, "setup": {"duration": 0.024752457999966282, "outcome": "passed"}, "call": {"duration": 0.738113825000255, "outcome": "passed"}, "teardown": {"duration": 0.00021111400019435678, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[openai/gpt-4o-mini-saturn]", "lineno": 96, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[openai/gpt-4o-mini-saturn]", "parametrize", "pytestmark", "openai/gpt-4o-mini-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "saturn"}, "setup": {"duration": 0.023303932000089844, "outcome": "passed"}, "call": {"duration": 1.2328131389999726, "outcome": "passed"}, "teardown": {"duration": 0.0003434619998188282, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-earth]", "lineno": 115, "outcome": "passed", "keywords": ["test_chat_streaming_basic[openai/gpt-4o-earth]", "parametrize", "pytestmark", "openai/gpt-4o-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "earth"}, "setup": {"duration": 0.024861412000063865, "outcome": "passed"}, "call": {"duration": 0.6608382389999861, "outcome": "passed"}, "teardown": {"duration": 0.0002502780002942018, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-saturn]", "lineno": 115, "outcome": "passed", "keywords": ["test_chat_streaming_basic[openai/gpt-4o-saturn]", "parametrize", "pytestmark", "openai/gpt-4o-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "saturn"}, "setup": {"duration": 0.024391553999976168, "outcome": "passed"}, "call": {"duration": 0.798923265999747, "outcome": "passed"}, "teardown": {"duration": 0.00025032799976543174, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-mini-earth]", "lineno": 115, "outcome": "passed", "keywords": ["test_chat_streaming_basic[openai/gpt-4o-mini-earth]", "parametrize", "pytestmark", "openai/gpt-4o-mini-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "earth"}, "setup": {"duration": 0.023274777000096947, "outcome": "passed"}, "call": {"duration": 0.49512473599997975, "outcome": "passed"}, "teardown": {"duration": 0.000313466000079643, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[openai/gpt-4o-mini-saturn]", "lineno": 115, "outcome": "passed", "keywords": ["test_chat_streaming_basic[openai/gpt-4o-mini-saturn]", "parametrize", "pytestmark", "openai/gpt-4o-mini-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "saturn"}, "setup": {"duration": 0.02444201800017254, "outcome": "passed"}, "call": {"duration": 0.926497737000318, "outcome": "passed"}, "teardown": {"duration": 0.0002592440000626084, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-messages_missing]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-messages_missing]", "parametrize", "pytestmark", "openai/gpt-4o-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "messages_missing"}, "setup": {"duration": 0.02449813199973505, "outcome": "passed"}, "call": {"duration": 0.0057626149996394815, "outcome": "passed"}, "teardown": {"duration": 0.00021345900040614652, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-messages_role_invalid]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-messages_role_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.023322475999975723, "outcome": "passed"}, "call": {"duration": 0.006818554999881599, "outcome": "passed"}, "teardown": {"duration": 0.0003301070000816253, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-tool_choice_invalid]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-tool_choice_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.029429245999835985, "outcome": "passed"}, "call": {"duration": 0.12164065800016033, "outcome": "passed"}, "teardown": {"duration": 0.00024797300011414336, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-tool_choice_no_tools]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-tool_choice_no_tools]", "parametrize", "pytestmark", "openai/gpt-4o-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.02281871500008492, "outcome": "passed"}, "call": {"duration": 0.09718602399971132, "outcome": "passed"}, "teardown": {"duration": 0.00032458600026075146, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-tools_type_invalid]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-tools_type_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.02392480099979366, "outcome": "passed"}, "call": {"duration": 0.11915395200003331, "outcome": "passed"}, "teardown": {"duration": 0.00023074099999575992, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-messages_missing]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-mini-messages_missing]", "parametrize", "pytestmark", "openai/gpt-4o-mini-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "messages_missing"}, "setup": {"duration": 0.02249291699990863, "outcome": "passed"}, "call": {"duration": 0.005550122999920859, "outcome": "passed"}, "teardown": {"duration": 0.00021104400002514012, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-messages_role_invalid]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-mini-messages_role_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-mini-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022405972999877122, "outcome": "passed"}, "call": {"duration": 0.006160819999877276, "outcome": "passed"}, "teardown": {"duration": 0.00022088299965616898, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tool_choice_invalid]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tool_choice_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-mini-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.022262065000177245, "outcome": "passed"}, "call": {"duration": 0.12069073499969818, "outcome": "passed"}, "teardown": {"duration": 0.00030513000001519686, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tool_choice_no_tools]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tool_choice_no_tools]", "parametrize", "pytestmark", "openai/gpt-4o-mini-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.022548528000243095, "outcome": "passed"}, "call": {"duration": 0.09547893999979351, "outcome": "passed"}, "teardown": {"duration": 0.00027033500009565614, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tools_type_invalid]", "lineno": 139, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[openai/gpt-4o-mini-tools_type_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-mini-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.022842880000098376, "outcome": "passed"}, "call": {"duration": 0.12137851600027716, "outcome": "passed"}, "teardown": {"duration": 0.00026242000012643985, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-messages_missing]", "lineno": 160, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-messages_missing]", "parametrize", "pytestmark", "openai/gpt-4o-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "messages_missing"}, "setup": {"duration": 0.022559139000350115, "outcome": "passed"}, "call": {"duration": 0.005400882000230922, "outcome": "passed"}, "teardown": {"duration": 0.00021755600027972832, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-messages_role_invalid]", "lineno": 160, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-messages_role_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022368934000041918, "outcome": "passed"}, "call": {"duration": 0.006411598999875423, "outcome": "passed"}, "teardown": {"duration": 0.0002521510000406124, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_invalid]", "lineno": 160, "outcome": "failed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.023164189999988594, "outcome": "passed"}, "call": {"duration": 0.010764541999833455, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 179, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 58, "message": "in __stream__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 50, "message": "in _iter_events"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 280, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 291, "message": "in _iter_chunks"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 897, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 951, "message": "in iter_raw"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_client.py", "lineno": 153, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 126, "message": "in __iter__"}, {"path": "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py", "lineno": 153, "message": "in __exit__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "RemoteProtocolError"}], "longrepr": "@contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n>           yield\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:127: in __iter__\n    for part in self._httpcore_stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407: in __iter__\n    raise exc from None\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403: in __iter__\n    for part in self._stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:342: in __iter__\n    raise exc\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:334: in __iter__\n    for chunk in self._connection._receive_response_body(**kwargs):\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:203: in _receive_response_body\n    event = self._receive_event(timeout=timeout)\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:213: in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmap = {<class 'h11._util.RemoteProtocolError'>: <class 'httpcore.RemoteProtocolError'>}\n\n    @contextlib.contextmanager\n    def map_exceptions(map: ExceptionMapping) -> typing.Iterator[None]:\n        try:\n            yield\n        except Exception as exc:  # noqa: PIE786\n            for from_exc, to_exc in map.items():\n                if isinstance(exc, from_exc):\n>                   raise to_exc(exc) from exc\nE                   httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14: RemoteProtocolError\n\nThe above exception was the direct cause of the following exception:\n\nrequest = <FixtureRequest for <Function test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_invalid]>>\nopenai_client = <openai.OpenAI object at 0x7ff879543610>\nmodel = 'openai/gpt-4o', provider = 'openai-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'tool_choice_invalid', 'input': {'messages': [{'content': 'Which planet do humans live on?', 'role': 'user'}], 'tool_choice': 'invalid'}, 'output': {'error': {'status_code': 400}}}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_chat_input_validation\"][\"test_params\"][\"case\"],\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_error_handling(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        with pytest.raises(APIError) as e:\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=case[\"input\"][\"messages\"],\n                stream=True,\n                tool_choice=case[\"input\"][\"tool_choice\"] if \"tool_choice\" in case[\"input\"] else None,\n                tools=case[\"input\"][\"tools\"] if \"tools\" in case[\"input\"] else None,\n            )\n>           for _chunk in response:\n\ntests/verifications/openai_api/test_chat_completion.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:58: in __stream__\n    for sse in iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:50: in _iter_events\n    yield from self._decoder.iter_bytes(self.response.iter_bytes())\n.venv/lib/python3.10/site-packages/openai/_streaming.py:280: in iter_bytes\n    for chunk in self._iter_chunks(iterator):\n.venv/lib/python3.10/site-packages/openai/_streaming.py:291: in _iter_chunks\n    for chunk in iterator:\n.venv/lib/python3.10/site-packages/httpx/_models.py:897: in iter_bytes\n    for raw_bytes in self.iter_raw():\n.venv/lib/python3.10/site-packages/httpx/_models.py:951: in iter_raw\n    for raw_stream_bytes in self.stream:\n.venv/lib/python3.10/site-packages/httpx/_client.py:153: in __iter__\n    for chunk in self._stream:\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:126: in __iter__\n    with map_httpcore_exceptions():\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n            yield\n        except Exception as exc:\n            mapped_exc = None\n    \n            for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n                if not isinstance(exc, from_exc):\n                    continue\n                # We want to map to the most specific exception we can find.\n                # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n                # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n                if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                    mapped_exc = to_exc\n    \n            if mapped_exc is None:  # pragma: no cover\n                raise\n    \n            message = str(exc)\n>           raise mapped_exc(message) from exc\nE           httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:118: RemoteProtocolError"}, "teardown": {"duration": 0.0002449779999551538, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_no_tools]", "lineno": 160, "outcome": "failed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_no_tools]", "parametrize", "pytestmark", "openai/gpt-4o-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.022405141000035655, "outcome": "passed"}, "call": {"duration": 0.010633175999828381, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 179, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 58, "message": "in __stream__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 50, "message": "in _iter_events"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 280, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 291, "message": "in _iter_chunks"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 897, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 951, "message": "in iter_raw"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_client.py", "lineno": 153, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 126, "message": "in __iter__"}, {"path": "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py", "lineno": 153, "message": "in __exit__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "RemoteProtocolError"}], "longrepr": "@contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n>           yield\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:127: in __iter__\n    for part in self._httpcore_stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407: in __iter__\n    raise exc from None\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403: in __iter__\n    for part in self._stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:342: in __iter__\n    raise exc\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:334: in __iter__\n    for chunk in self._connection._receive_response_body(**kwargs):\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:203: in _receive_response_body\n    event = self._receive_event(timeout=timeout)\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:213: in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmap = {<class 'h11._util.RemoteProtocolError'>: <class 'httpcore.RemoteProtocolError'>}\n\n    @contextlib.contextmanager\n    def map_exceptions(map: ExceptionMapping) -> typing.Iterator[None]:\n        try:\n            yield\n        except Exception as exc:  # noqa: PIE786\n            for from_exc, to_exc in map.items():\n                if isinstance(exc, from_exc):\n>                   raise to_exc(exc) from exc\nE                   httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14: RemoteProtocolError\n\nThe above exception was the direct cause of the following exception:\n\nrequest = <FixtureRequest for <Function test_chat_streaming_error_handling[openai/gpt-4o-tool_choice_no_tools]>>\nopenai_client = <openai.OpenAI object at 0x7ff879322380>\nmodel = 'openai/gpt-4o', provider = 'openai-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'tool_choice_no_tools', 'input': {'messages': [{'content': 'Which planet do humans live on?', 'role': 'user'}], 'tool_choice': 'required'}, 'output': {'error': {'status_code': 400}}}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_chat_input_validation\"][\"test_params\"][\"case\"],\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_error_handling(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        with pytest.raises(APIError) as e:\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=case[\"input\"][\"messages\"],\n                stream=True,\n                tool_choice=case[\"input\"][\"tool_choice\"] if \"tool_choice\" in case[\"input\"] else None,\n                tools=case[\"input\"][\"tools\"] if \"tools\" in case[\"input\"] else None,\n            )\n>           for _chunk in response:\n\ntests/verifications/openai_api/test_chat_completion.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:58: in __stream__\n    for sse in iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:50: in _iter_events\n    yield from self._decoder.iter_bytes(self.response.iter_bytes())\n.venv/lib/python3.10/site-packages/openai/_streaming.py:280: in iter_bytes\n    for chunk in self._iter_chunks(iterator):\n.venv/lib/python3.10/site-packages/openai/_streaming.py:291: in _iter_chunks\n    for chunk in iterator:\n.venv/lib/python3.10/site-packages/httpx/_models.py:897: in iter_bytes\n    for raw_bytes in self.iter_raw():\n.venv/lib/python3.10/site-packages/httpx/_models.py:951: in iter_raw\n    for raw_stream_bytes in self.stream:\n.venv/lib/python3.10/site-packages/httpx/_client.py:153: in __iter__\n    for chunk in self._stream:\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:126: in __iter__\n    with map_httpcore_exceptions():\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n            yield\n        except Exception as exc:\n            mapped_exc = None\n    \n            for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n                if not isinstance(exc, from_exc):\n                    continue\n                # We want to map to the most specific exception we can find.\n                # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n                # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n                if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                    mapped_exc = to_exc\n    \n            if mapped_exc is None:  # pragma: no cover\n                raise\n    \n            message = str(exc)\n>           raise mapped_exc(message) from exc\nE           httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:118: RemoteProtocolError"}, "teardown": {"duration": 0.000264543999946909, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-tools_type_invalid]", "lineno": 160, "outcome": "failed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-tools_type_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.0224912509997921, "outcome": "passed"}, "call": {"duration": 0.010900676999881398, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 179, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 58, "message": "in __stream__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 50, "message": "in _iter_events"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 280, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 291, "message": "in _iter_chunks"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 897, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 951, "message": "in iter_raw"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_client.py", "lineno": 153, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 126, "message": "in __iter__"}, {"path": "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py", "lineno": 153, "message": "in __exit__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "RemoteProtocolError"}], "longrepr": "@contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n>           yield\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:127: in __iter__\n    for part in self._httpcore_stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407: in __iter__\n    raise exc from None\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403: in __iter__\n    for part in self._stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:342: in __iter__\n    raise exc\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:334: in __iter__\n    for chunk in self._connection._receive_response_body(**kwargs):\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:203: in _receive_response_body\n    event = self._receive_event(timeout=timeout)\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:213: in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmap = {<class 'h11._util.RemoteProtocolError'>: <class 'httpcore.RemoteProtocolError'>}\n\n    @contextlib.contextmanager\n    def map_exceptions(map: ExceptionMapping) -> typing.Iterator[None]:\n        try:\n            yield\n        except Exception as exc:  # noqa: PIE786\n            for from_exc, to_exc in map.items():\n                if isinstance(exc, from_exc):\n>                   raise to_exc(exc) from exc\nE                   httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14: RemoteProtocolError\n\nThe above exception was the direct cause of the following exception:\n\nrequest = <FixtureRequest for <Function test_chat_streaming_error_handling[openai/gpt-4o-tools_type_invalid]>>\nopenai_client = <openai.OpenAI object at 0x7ff878fe3d30>\nmodel = 'openai/gpt-4o', provider = 'openai-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'tools_type_invalid', 'input': {'messages': [{'content': 'Which planet do humans live on?', 'role': 'user'}], 'tools': [{'type': 'invalid'}]}, 'output': {'error': {'status_code': 400}}}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_chat_input_validation\"][\"test_params\"][\"case\"],\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_error_handling(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        with pytest.raises(APIError) as e:\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=case[\"input\"][\"messages\"],\n                stream=True,\n                tool_choice=case[\"input\"][\"tool_choice\"] if \"tool_choice\" in case[\"input\"] else None,\n                tools=case[\"input\"][\"tools\"] if \"tools\" in case[\"input\"] else None,\n            )\n>           for _chunk in response:\n\ntests/verifications/openai_api/test_chat_completion.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:58: in __stream__\n    for sse in iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:50: in _iter_events\n    yield from self._decoder.iter_bytes(self.response.iter_bytes())\n.venv/lib/python3.10/site-packages/openai/_streaming.py:280: in iter_bytes\n    for chunk in self._iter_chunks(iterator):\n.venv/lib/python3.10/site-packages/openai/_streaming.py:291: in _iter_chunks\n    for chunk in iterator:\n.venv/lib/python3.10/site-packages/httpx/_models.py:897: in iter_bytes\n    for raw_bytes in self.iter_raw():\n.venv/lib/python3.10/site-packages/httpx/_models.py:951: in iter_raw\n    for raw_stream_bytes in self.stream:\n.venv/lib/python3.10/site-packages/httpx/_client.py:153: in __iter__\n    for chunk in self._stream:\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:126: in __iter__\n    with map_httpcore_exceptions():\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n            yield\n        except Exception as exc:\n            mapped_exc = None\n    \n            for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n                if not isinstance(exc, from_exc):\n                    continue\n                # We want to map to the most specific exception we can find.\n                # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n                # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n                if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                    mapped_exc = to_exc\n    \n            if mapped_exc is None:  # pragma: no cover\n                raise\n    \n            message = str(exc)\n>           raise mapped_exc(message) from exc\nE           httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:118: RemoteProtocolError"}, "teardown": {"duration": 0.0002459190000081435, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-messages_missing]", "lineno": 160, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-mini-messages_missing]", "parametrize", "pytestmark", "openai/gpt-4o-mini-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "messages_missing"}, "setup": {"duration": 0.022330181000143057, "outcome": "passed"}, "call": {"duration": 0.006249225999908958, "outcome": "passed"}, "teardown": {"duration": 0.0002306810001755366, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-messages_role_invalid]", "lineno": 160, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-mini-messages_role_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-mini-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022202813000149035, "outcome": "passed"}, "call": {"duration": 0.007233174000248255, "outcome": "passed"}, "teardown": {"duration": 0.00021904899995206506, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_invalid]", "lineno": 160, "outcome": "failed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-mini-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.06117987700008598, "outcome": "passed"}, "call": {"duration": 0.010751347999757854, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 179, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 58, "message": "in __stream__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 50, "message": "in _iter_events"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 280, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 291, "message": "in _iter_chunks"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 897, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 951, "message": "in iter_raw"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_client.py", "lineno": 153, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 126, "message": "in __iter__"}, {"path": "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py", "lineno": 153, "message": "in __exit__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "RemoteProtocolError"}], "longrepr": "@contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n>           yield\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:127: in __iter__\n    for part in self._httpcore_stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407: in __iter__\n    raise exc from None\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403: in __iter__\n    for part in self._stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:342: in __iter__\n    raise exc\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:334: in __iter__\n    for chunk in self._connection._receive_response_body(**kwargs):\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:203: in _receive_response_body\n    event = self._receive_event(timeout=timeout)\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:213: in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmap = {<class 'h11._util.RemoteProtocolError'>: <class 'httpcore.RemoteProtocolError'>}\n\n    @contextlib.contextmanager\n    def map_exceptions(map: ExceptionMapping) -> typing.Iterator[None]:\n        try:\n            yield\n        except Exception as exc:  # noqa: PIE786\n            for from_exc, to_exc in map.items():\n                if isinstance(exc, from_exc):\n>                   raise to_exc(exc) from exc\nE                   httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14: RemoteProtocolError\n\nThe above exception was the direct cause of the following exception:\n\nrequest = <FixtureRequest for <Function test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_invalid]>>\nopenai_client = <openai.OpenAI object at 0x7ff87910cca0>\nmodel = 'openai/gpt-4o-mini', provider = 'openai-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'tool_choice_invalid', 'input': {'messages': [{'content': 'Which planet do humans live on?', 'role': 'user'}], 'tool_choice': 'invalid'}, 'output': {'error': {'status_code': 400}}}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_chat_input_validation\"][\"test_params\"][\"case\"],\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_error_handling(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        with pytest.raises(APIError) as e:\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=case[\"input\"][\"messages\"],\n                stream=True,\n                tool_choice=case[\"input\"][\"tool_choice\"] if \"tool_choice\" in case[\"input\"] else None,\n                tools=case[\"input\"][\"tools\"] if \"tools\" in case[\"input\"] else None,\n            )\n>           for _chunk in response:\n\ntests/verifications/openai_api/test_chat_completion.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:58: in __stream__\n    for sse in iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:50: in _iter_events\n    yield from self._decoder.iter_bytes(self.response.iter_bytes())\n.venv/lib/python3.10/site-packages/openai/_streaming.py:280: in iter_bytes\n    for chunk in self._iter_chunks(iterator):\n.venv/lib/python3.10/site-packages/openai/_streaming.py:291: in _iter_chunks\n    for chunk in iterator:\n.venv/lib/python3.10/site-packages/httpx/_models.py:897: in iter_bytes\n    for raw_bytes in self.iter_raw():\n.venv/lib/python3.10/site-packages/httpx/_models.py:951: in iter_raw\n    for raw_stream_bytes in self.stream:\n.venv/lib/python3.10/site-packages/httpx/_client.py:153: in __iter__\n    for chunk in self._stream:\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:126: in __iter__\n    with map_httpcore_exceptions():\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n            yield\n        except Exception as exc:\n            mapped_exc = None\n    \n            for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n                if not isinstance(exc, from_exc):\n                    continue\n                # We want to map to the most specific exception we can find.\n                # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n                # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n                if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                    mapped_exc = to_exc\n    \n            if mapped_exc is None:  # pragma: no cover\n                raise\n    \n            message = str(exc)\n>           raise mapped_exc(message) from exc\nE           httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:118: RemoteProtocolError"}, "teardown": {"duration": 0.0002388959997006168, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_no_tools]", "lineno": 160, "outcome": "failed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_no_tools]", "parametrize", "pytestmark", "openai/gpt-4o-mini-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.022449143000358163, "outcome": "passed"}, "call": {"duration": 0.010488098999758222, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 179, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 58, "message": "in __stream__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 50, "message": "in _iter_events"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 280, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 291, "message": "in _iter_chunks"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 897, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 951, "message": "in iter_raw"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_client.py", "lineno": 153, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 126, "message": "in __iter__"}, {"path": "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py", "lineno": 153, "message": "in __exit__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "RemoteProtocolError"}], "longrepr": "@contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n>           yield\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:127: in __iter__\n    for part in self._httpcore_stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407: in __iter__\n    raise exc from None\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403: in __iter__\n    for part in self._stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:342: in __iter__\n    raise exc\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:334: in __iter__\n    for chunk in self._connection._receive_response_body(**kwargs):\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:203: in _receive_response_body\n    event = self._receive_event(timeout=timeout)\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:213: in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmap = {<class 'h11._util.RemoteProtocolError'>: <class 'httpcore.RemoteProtocolError'>}\n\n    @contextlib.contextmanager\n    def map_exceptions(map: ExceptionMapping) -> typing.Iterator[None]:\n        try:\n            yield\n        except Exception as exc:  # noqa: PIE786\n            for from_exc, to_exc in map.items():\n                if isinstance(exc, from_exc):\n>                   raise to_exc(exc) from exc\nE                   httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14: RemoteProtocolError\n\nThe above exception was the direct cause of the following exception:\n\nrequest = <FixtureRequest for <Function test_chat_streaming_error_handling[openai/gpt-4o-mini-tool_choice_no_tools]>>\nopenai_client = <openai.OpenAI object at 0x7ff879221ba0>\nmodel = 'openai/gpt-4o-mini', provider = 'openai-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'tool_choice_no_tools', 'input': {'messages': [{'content': 'Which planet do humans live on?', 'role': 'user'}], 'tool_choice': 'required'}, 'output': {'error': {'status_code': 400}}}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_chat_input_validation\"][\"test_params\"][\"case\"],\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_error_handling(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        with pytest.raises(APIError) as e:\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=case[\"input\"][\"messages\"],\n                stream=True,\n                tool_choice=case[\"input\"][\"tool_choice\"] if \"tool_choice\" in case[\"input\"] else None,\n                tools=case[\"input\"][\"tools\"] if \"tools\" in case[\"input\"] else None,\n            )\n>           for _chunk in response:\n\ntests/verifications/openai_api/test_chat_completion.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:58: in __stream__\n    for sse in iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:50: in _iter_events\n    yield from self._decoder.iter_bytes(self.response.iter_bytes())\n.venv/lib/python3.10/site-packages/openai/_streaming.py:280: in iter_bytes\n    for chunk in self._iter_chunks(iterator):\n.venv/lib/python3.10/site-packages/openai/_streaming.py:291: in _iter_chunks\n    for chunk in iterator:\n.venv/lib/python3.10/site-packages/httpx/_models.py:897: in iter_bytes\n    for raw_bytes in self.iter_raw():\n.venv/lib/python3.10/site-packages/httpx/_models.py:951: in iter_raw\n    for raw_stream_bytes in self.stream:\n.venv/lib/python3.10/site-packages/httpx/_client.py:153: in __iter__\n    for chunk in self._stream:\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:126: in __iter__\n    with map_httpcore_exceptions():\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n            yield\n        except Exception as exc:\n            mapped_exc = None\n    \n            for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n                if not isinstance(exc, from_exc):\n                    continue\n                # We want to map to the most specific exception we can find.\n                # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n                # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n                if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                    mapped_exc = to_exc\n    \n            if mapped_exc is None:  # pragma: no cover\n                raise\n    \n            message = str(exc)\n>           raise mapped_exc(message) from exc\nE           httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:118: RemoteProtocolError"}, "teardown": {"duration": 0.0002579619999778515, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[openai/gpt-4o-mini-tools_type_invalid]", "lineno": 160, "outcome": "failed", "keywords": ["test_chat_streaming_error_handling[openai/gpt-4o-mini-tools_type_invalid]", "parametrize", "pytestmark", "openai/gpt-4o-mini-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.02255580299970461, "outcome": "passed"}, "call": {"duration": 0.01117421800017837, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 179, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 58, "message": "in __stream__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 50, "message": "in _iter_events"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 280, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 291, "message": "in _iter_chunks"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 897, "message": "in iter_bytes"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_models.py", "lineno": 951, "message": "in iter_raw"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_client.py", "lineno": 153, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 126, "message": "in __iter__"}, {"path": "/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py", "lineno": 153, "message": "in __exit__"}, {"path": ".venv/lib/python3.10/site-packages/httpx/_transports/default.py", "lineno": 118, "message": "RemoteProtocolError"}], "longrepr": "@contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n>           yield\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:101: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:127: in __iter__\n    for part in self._httpcore_stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:407: in __iter__\n    raise exc from None\n.venv/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:403: in __iter__\n    for part in self._stream:\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:342: in __iter__\n    raise exc\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:334: in __iter__\n    for chunk in self._connection._receive_response_body(**kwargs):\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:203: in _receive_response_body\n    event = self._receive_event(timeout=timeout)\n.venv/lib/python3.10/site-packages/httpcore/_sync/http11.py:213: in _receive_event\n    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmap = {<class 'h11._util.RemoteProtocolError'>: <class 'httpcore.RemoteProtocolError'>}\n\n    @contextlib.contextmanager\n    def map_exceptions(map: ExceptionMapping) -> typing.Iterator[None]:\n        try:\n            yield\n        except Exception as exc:  # noqa: PIE786\n            for from_exc, to_exc in map.items():\n                if isinstance(exc, from_exc):\n>                   raise to_exc(exc) from exc\nE                   httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpcore/_exceptions.py:14: RemoteProtocolError\n\nThe above exception was the direct cause of the following exception:\n\nrequest = <FixtureRequest for <Function test_chat_streaming_error_handling[openai/gpt-4o-mini-tools_type_invalid]>>\nopenai_client = <openai.OpenAI object at 0x7ff8793b3be0>\nmodel = 'openai/gpt-4o-mini', provider = 'openai-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'tools_type_invalid', 'input': {'messages': [{'content': 'Which planet do humans live on?', 'role': 'user'}], 'tools': [{'type': 'invalid'}]}, 'output': {'error': {'status_code': 400}}}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_chat_input_validation\"][\"test_params\"][\"case\"],\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_error_handling(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        with pytest.raises(APIError) as e:\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=case[\"input\"][\"messages\"],\n                stream=True,\n                tool_choice=case[\"input\"][\"tool_choice\"] if \"tool_choice\" in case[\"input\"] else None,\n                tools=case[\"input\"][\"tools\"] if \"tools\" in case[\"input\"] else None,\n            )\n>           for _chunk in response:\n\ntests/verifications/openai_api/test_chat_completion.py:179: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:58: in __stream__\n    for sse in iterator:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:50: in _iter_events\n    yield from self._decoder.iter_bytes(self.response.iter_bytes())\n.venv/lib/python3.10/site-packages/openai/_streaming.py:280: in iter_bytes\n    for chunk in self._iter_chunks(iterator):\n.venv/lib/python3.10/site-packages/openai/_streaming.py:291: in _iter_chunks\n    for chunk in iterator:\n.venv/lib/python3.10/site-packages/httpx/_models.py:897: in iter_bytes\n    for raw_bytes in self.iter_raw():\n.venv/lib/python3.10/site-packages/httpx/_models.py:951: in iter_raw\n    for raw_stream_bytes in self.stream:\n.venv/lib/python3.10/site-packages/httpx/_client.py:153: in __iter__\n    for chunk in self._stream:\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:126: in __iter__\n    with map_httpcore_exceptions():\n/opt/hostedtoolcache/Python/3.10.17/x64/lib/python3.10/contextlib.py:153: in __exit__\n    self.gen.throw(typ, value, traceback)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\n    @contextlib.contextmanager\n    def map_httpcore_exceptions() -> typing.Iterator[None]:\n        global HTTPCORE_EXC_MAP\n        if len(HTTPCORE_EXC_MAP) == 0:\n            HTTPCORE_EXC_MAP = _load_httpcore_exceptions()\n        try:\n            yield\n        except Exception as exc:\n            mapped_exc = None\n    \n            for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n                if not isinstance(exc, from_exc):\n                    continue\n                # We want to map to the most specific exception we can find.\n                # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n                # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n                if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                    mapped_exc = to_exc\n    \n            if mapped_exc is None:  # pragma: no cover\n                raise\n    \n            message = str(exc)\n>           raise mapped_exc(message) from exc\nE           httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)\n\n.venv/lib/python3.10/site-packages/httpx/_transports/default.py:118: RemoteProtocolError"}, "teardown": {"duration": 0.00023782499965818715, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[openai/gpt-4o-case0]", "lineno": 183, "outcome": "passed", "keywords": ["test_chat_non_streaming_image[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.022491061999971862, "outcome": "passed"}, "call": {"duration": 4.686461872000109, "outcome": "passed"}, "teardown": {"duration": 0.00020500299979175907, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[openai/gpt-4o-mini-case0]", "lineno": 183, "outcome": "passed", "keywords": ["test_chat_non_streaming_image[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.02287208399957308, "outcome": "passed"}, "call": {"duration": 3.6724105489997783, "outcome": "passed"}, "teardown": {"duration": 0.00020900999970763223, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[openai/gpt-4o-case0]", "lineno": 202, "outcome": "passed", "keywords": ["test_chat_streaming_image[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.022965226999986044, "outcome": "passed"}, "call": {"duration": 4.448459581999941, "outcome": "passed"}, "teardown": {"duration": 0.00020823900013056118, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[openai/gpt-4o-mini-case0]", "lineno": 202, "outcome": "passed", "keywords": ["test_chat_streaming_image[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.022317607000331918, "outcome": "passed"}, "call": {"duration": 3.157543299000281, "outcome": "passed"}, "teardown": {"duration": 0.00020213700008753221, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-calendar]", "lineno": 226, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[openai/gpt-4o-calendar]", "parametrize", "pytestmark", "openai/gpt-4o-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "calendar"}, "setup": {"duration": 0.023396062000301754, "outcome": "passed"}, "call": {"duration": 0.7415731209998739, "outcome": "passed"}, "teardown": {"duration": 0.00020156599975962308, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-math]", "lineno": 226, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[openai/gpt-4o-math]", "parametrize", "pytestmark", "openai/gpt-4o-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "math"}, "setup": {"duration": 0.022700331000123697, "outcome": "passed"}, "call": {"duration": 4.552969286000007, "outcome": "passed"}, "teardown": {"duration": 0.00021612399996229215, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-mini-calendar]", "lineno": 226, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[openai/gpt-4o-mini-calendar]", "parametrize", "pytestmark", "openai/gpt-4o-mini-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "calendar"}, "setup": {"duration": 0.022228981000353087, "outcome": "passed"}, "call": {"duration": 0.9621351119999417, "outcome": "passed"}, "teardown": {"duration": 0.0002279760001329123, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[openai/gpt-4o-mini-math]", "lineno": 226, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[openai/gpt-4o-mini-math]", "parametrize", "pytestmark", "openai/gpt-4o-mini-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "math"}, "setup": {"duration": 0.02223851899998408, "outcome": "passed"}, "call": {"duration": 2.7840370769999936, "outcome": "passed"}, "teardown": {"duration": 0.00020097500009796931, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-calendar]", "lineno": 249, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[openai/gpt-4o-calendar]", "parametrize", "pytestmark", "openai/gpt-4o-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "calendar"}, "setup": {"duration": 0.022741165999832447, "outcome": "passed"}, "call": {"duration": 0.9653029770001922, "outcome": "passed"}, "teardown": {"duration": 0.0001951640001607302, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-math]", "lineno": 249, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[openai/gpt-4o-math]", "parametrize", "pytestmark", "openai/gpt-4o-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "math"}, "setup": {"duration": 0.022845020000204386, "outcome": "passed"}, "call": {"duration": 4.348592586999985, "outcome": "passed"}, "teardown": {"duration": 0.00019816999974864302, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-mini-calendar]", "lineno": 249, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[openai/gpt-4o-mini-calendar]", "parametrize", "pytestmark", "openai/gpt-4o-mini-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "calendar"}, "setup": {"duration": 0.0225934119998783, "outcome": "passed"}, "call": {"duration": 3.8191479219999565, "outcome": "passed"}, "teardown": {"duration": 0.0002000539998334716, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[openai/gpt-4o-mini-math]", "lineno": 249, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[openai/gpt-4o-mini-math]", "parametrize", "pytestmark", "openai/gpt-4o-mini-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "math"}, "setup": {"duration": 0.02314040400005979, "outcome": "passed"}, "call": {"duration": 8.328419371999644, "outcome": "passed"}, "teardown": {"duration": 0.00022719399976267596, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[openai/gpt-4o-case0]", "lineno": 271, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.02321544400001585, "outcome": "passed"}, "call": {"duration": 1.257721629000116, "outcome": "passed"}, "teardown": {"duration": 0.0002744119997259986, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[openai/gpt-4o-mini-case0]", "lineno": 271, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.023879183999724773, "outcome": "passed"}, "call": {"duration": 2.996318540000175, "outcome": "passed"}, "teardown": {"duration": 0.0003270209999755025, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[openai/gpt-4o-case0]", "lineno": 295, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.023907802999929118, "outcome": "passed"}, "call": {"duration": 1.1027862209998602, "outcome": "passed"}, "teardown": {"duration": 0.00030428800027948455, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[openai/gpt-4o-mini-case0]", "lineno": 295, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.023083604000021296, "outcome": "passed"}, "call": {"duration": 0.9735001310000371, "outcome": "passed"}, "teardown": {"duration": 0.0002933780001512787, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[openai/gpt-4o-case0]", "lineno": 323, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_required[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.022927742000319995, "outcome": "passed"}, "call": {"duration": 0.5833974909996869, "outcome": "passed"}, "teardown": {"duration": 0.00032633899991196813, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[openai/gpt-4o-mini-case0]", "lineno": 323, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_required[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.022737538000001223, "outcome": "passed"}, "call": {"duration": 0.8239597510000749, "outcome": "passed"}, "teardown": {"duration": 0.0003298360002190748, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[openai/gpt-4o-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_required[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.02326462100018034, "outcome": "passed"}, "call": {"duration": 1.1013268199999402, "outcome": "passed"}, "teardown": {"duration": 0.0002144909999515221, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[openai/gpt-4o-mini-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_required[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.032225137000295945, "outcome": "passed"}, "call": {"duration": 0.7411594969998987, "outcome": "passed"}, "teardown": {"duration": 0.0002945500000350876, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[openai/gpt-4o-case0]", "lineno": 374, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.023603698999977496, "outcome": "passed"}, "call": {"duration": 0.6239617510000244, "outcome": "passed"}, "teardown": {"duration": 0.0003411269999560318, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[openai/gpt-4o-mini-case0]", "lineno": 374, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.023128460999942035, "outcome": "passed"}, "call": {"duration": 0.5985959059999004, "outcome": "passed"}, "teardown": {"duration": 0.00019350200000189943, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[openai/gpt-4o-case0]", "lineno": 397, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[openai/gpt-4o-case0]", "parametrize", "pytestmark", "openai/gpt-4o-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "case0"}, "setup": {"duration": 0.02318518599986419, "outcome": "passed"}, "call": {"duration": 1.4637718799999675, "outcome": "passed"}, "teardown": {"duration": 0.0002055640002254222, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[openai/gpt-4o-mini-case0]", "lineno": 397, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[openai/gpt-4o-mini-case0]", "parametrize", "pytestmark", "openai/gpt-4o-mini-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "case0"}, "setup": {"duration": 0.022777395000048273, "outcome": "passed"}, "call": {"duration": 0.8630974329998935, "outcome": "passed"}, "teardown": {"duration": 0.0002023179999923741, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-text_then_weather_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-text_then_weather_tool]", "parametrize", "pytestmark", "openai/gpt-4o-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.023741886999687267, "outcome": "passed"}, "call": {"duration": 2.249378701999831, "outcome": "passed"}, "teardown": {"duration": 0.00023294499987969175, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-weather_tool_then_text]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-weather_tool_then_text]", "parametrize", "pytestmark", "openai/gpt-4o-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.024490454999977374, "outcome": "passed"}, "call": {"duration": 1.895185624000078, "outcome": "passed"}, "teardown": {"duration": 0.000309928999740805, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-add_product_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-add_product_tool]", "parametrize", "pytestmark", "openai/gpt-4o-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "add_product_tool"}, "setup": {"duration": 0.024023742999816022, "outcome": "passed"}, "call": {"duration": 1.624827057999937, "outcome": "passed"}, "teardown": {"duration": 0.00025373400012540515, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-get_then_create_event_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-get_then_create_event_tool]", "parametrize", "pytestmark", "openai/gpt-4o-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022650528000212944, "outcome": "passed"}, "call": {"duration": 4.826603794000221, "outcome": "passed"}, "teardown": {"duration": 0.00022880699998495402, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-compare_monthly_expense_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-compare_monthly_expense_tool]", "parametrize", "pytestmark", "openai/gpt-4o-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022913574000085646, "outcome": "passed"}, "call": {"duration": 4.6323014099998545, "outcome": "passed"}, "teardown": {"duration": 0.00019234999990658252, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-text_then_weather_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-text_then_weather_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.024411856999904558, "outcome": "passed"}, "call": {"duration": 1.8915746820002823, "outcome": "passed"}, "teardown": {"duration": 0.00019652700029837433, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-weather_tool_then_text]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-weather_tool_then_text]", "parametrize", "pytestmark", "openai/gpt-4o-mini-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.02423745099986263, "outcome": "passed"}, "call": {"duration": 1.4786329329999717, "outcome": "passed"}, "teardown": {"duration": 0.00031233399977281806, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-add_product_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-add_product_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "add_product_tool"}, "setup": {"duration": 0.023977906000254734, "outcome": "passed"}, "call": {"duration": 1.8105737370001407, "outcome": "passed"}, "teardown": {"duration": 0.00019731900010810932, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-get_then_create_event_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-get_then_create_event_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.02382794400000421, "outcome": "passed"}, "call": {"duration": 4.021435751000354, "outcome": "passed"}, "teardown": {"duration": 0.0002675699997780612, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-compare_monthly_expense_tool]", "lineno": 425, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-compare_monthly_expense_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.023067684999659832, "outcome": "passed"}, "call": {"duration": 2.781348818999959, "outcome": "passed"}, "teardown": {"duration": 0.00020495299986578175, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-text_then_weather_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-text_then_weather_tool]", "parametrize", "pytestmark", "openai/gpt-4o-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022899589999724412, "outcome": "passed"}, "call": {"duration": 2.0323709879999114, "outcome": "passed"}, "teardown": {"duration": 0.00031089100002645864, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-weather_tool_then_text]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-weather_tool_then_text]", "parametrize", "pytestmark", "openai/gpt-4o-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.022436956000092323, "outcome": "passed"}, "call": {"duration": 1.4401297059998797, "outcome": "passed"}, "teardown": {"duration": 0.00019832099997074693, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-add_product_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-add_product_tool]", "parametrize", "pytestmark", "openai/gpt-4o-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "add_product_tool"}, "setup": {"duration": 0.022514487000080408, "outcome": "passed"}, "call": {"duration": 2.083725815999969, "outcome": "passed"}, "teardown": {"duration": 0.00022513000021717744, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-get_then_create_event_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-get_then_create_event_tool]", "parametrize", "pytestmark", "openai/gpt-4o-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022730310000042664, "outcome": "passed"}, "call": {"duration": 4.88710121000031, "outcome": "passed"}, "teardown": {"duration": 0.0003839780001726467, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-compare_monthly_expense_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-compare_monthly_expense_tool]", "parametrize", "pytestmark", "openai/gpt-4o-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.023457157999928313, "outcome": "passed"}, "call": {"duration": 3.0782448200002364, "outcome": "passed"}, "teardown": {"duration": 0.00022866700010126806, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-text_then_weather_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-text_then_weather_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.0242246940001678, "outcome": "passed"}, "call": {"duration": 2.606224271999963, "outcome": "passed"}, "teardown": {"duration": 0.0002601260002847994, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-weather_tool_then_text]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-weather_tool_then_text]", "parametrize", "pytestmark", "openai/gpt-4o-mini-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.024020030999963637, "outcome": "passed"}, "call": {"duration": 5.230015010999978, "outcome": "passed"}, "teardown": {"duration": 0.00022454899999502231, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-add_product_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-add_product_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "add_product_tool"}, "setup": {"duration": 0.023665320000418433, "outcome": "passed"}, "call": {"duration": 2.0366147400000045, "outcome": "passed"}, "teardown": {"duration": 0.00020061400027771015, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-get_then_create_event_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-get_then_create_event_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022913105000043288, "outcome": "passed"}, "call": {"duration": 4.322371766000288, "outcome": "passed"}, "teardown": {"duration": 0.0002812749999066, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-compare_monthly_expense_tool]", "lineno": 516, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[openai/gpt-4o-mini-compare_monthly_expense_tool]", "parametrize", "pytestmark", "openai/gpt-4o-mini-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.023512304999712796, "outcome": "passed"}, "call": {"duration": 2.734092389000125, "outcome": "passed"}, "teardown": {"duration": 0.00030239500028983457, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-stream=False]", "lineno": 599, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[openai/gpt-4o-stream=False]", "parametrize", "pytestmark", "openai/gpt-4o-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "stream=False"}, "setup": {"duration": 0.02472089299999425, "outcome": "passed"}, "call": {"duration": 8.02911803699999, "outcome": "passed"}, "teardown": {"duration": 0.00020930200025759405, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-stream=True]", "lineno": 599, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[openai/gpt-4o-stream=True]", "parametrize", "pytestmark", "openai/gpt-4o-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o", "case_id": "stream=True"}, "setup": {"duration": 0.02551499099990906, "outcome": "passed"}, "call": {"duration": 7.375463232000129, "outcome": "passed"}, "teardown": {"duration": 0.00020505300017248373, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-mini-stream=False]", "lineno": 599, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[openai/gpt-4o-mini-stream=False]", "parametrize", "pytestmark", "openai/gpt-4o-mini-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "stream=False"}, "setup": {"duration": 0.024443263000193838, "outcome": "passed"}, "call": {"duration": 7.83400624099977, "outcome": "passed"}, "teardown": {"duration": 0.00020322899990787846, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[openai/gpt-4o-mini-stream=True]", "lineno": 599, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[openai/gpt-4o-mini-stream=True]", "parametrize", "pytestmark", "openai/gpt-4o-mini-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "openai/gpt-4o-mini", "case_id": "stream=True"}, "setup": {"duration": 0.024717541999962123, "outcome": "passed"}, "call": {"duration": 7.637368702000003, "outcome": "passed"}, "teardown": {"duration": 0.00200551500029178, "outcome": "passed"}}]}