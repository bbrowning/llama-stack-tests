{"created": 1747248434.4378192, "duration": 216.91784644126892, "exitcode": 1, "root": "/home/runner/work/llama-stack-tests/llama-stack-tests", "environment": {}, "summary": {"passed": 101, "skipped": 4, "failed": 9, "total": 114, "collected": 114}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py", "type": "Module"}]}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py", "outcome": "passed", "result": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 133}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 133}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 133}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 152}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 152}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 152}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 221}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 221}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 221}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 245}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 245}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 245}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 273}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 273}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 273}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 297}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 297}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 297}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 324}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 324}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 324}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True]", "type": "Function", "lineno": 549}]}], "tests": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "earth"}, "setup": {"duration": 0.053618228999994244, "outcome": "passed"}, "call": {"duration": 0.5422705940000014, "outcome": "passed"}, "teardown": {"duration": 0.00022375900005044969, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "saturn"}, "setup": {"duration": 0.023115431000064746, "outcome": "passed"}, "call": {"duration": 0.5436049959999991, "outcome": "passed"}, "teardown": {"duration": 0.00026124799990157044, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "earth"}, "setup": {"duration": 0.02319219499997871, "outcome": "passed"}, "call": {"duration": 0.3985843799999884, "outcome": "passed"}, "teardown": {"duration": 0.00018977399997766042, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "saturn"}, "setup": {"duration": 0.022994748000087384, "outcome": "passed"}, "call": {"duration": 0.24613087000000178, "outcome": "passed"}, "teardown": {"duration": 0.000206075000050987, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "earth"}, "setup": {"duration": 0.024055238999949324, "outcome": "passed"}, "call": {"duration": 0.7234054240000205, "outcome": "passed"}, "teardown": {"duration": 0.0003064720000338639, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "saturn"}, "setup": {"duration": 0.02384339299999283, "outcome": "passed"}, "call": {"duration": 0.30640163200007464, "outcome": "passed"}, "teardown": {"duration": 0.00023602099997788173, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "earth"}, "setup": {"duration": 0.02389557000003606, "outcome": "passed"}, "call": {"duration": 0.44001293100006933, "outcome": "passed"}, "teardown": {"duration": 0.00018081700000038836, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "saturn"}, "setup": {"duration": 0.023045931999945424, "outcome": "passed"}, "call": {"duration": 0.9616169849999778, "outcome": "passed"}, "teardown": {"duration": 0.0003484019999859811, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "earth"}, "setup": {"duration": 0.022770464999894102, "outcome": "passed"}, "call": {"duration": 0.4537941269999237, "outcome": "passed"}, "teardown": {"duration": 0.00021336999998311512, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "saturn"}, "setup": {"duration": 0.022939790999998877, "outcome": "passed"}, "call": {"duration": 0.3413682380000864, "outcome": "passed"}, "teardown": {"duration": 0.0003043399999569374, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "earth"}, "setup": {"duration": 0.02220454600001176, "outcome": "passed"}, "call": {"duration": 0.8879466299999876, "outcome": "passed"}, "teardown": {"duration": 0.00024202299994158238, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "saturn"}, "setup": {"duration": 0.022536887000001116, "outcome": "passed"}, "call": {"duration": 1.014084655999909, "outcome": "passed"}, "teardown": {"duration": 0.00018692999992708792, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_missing"}, "setup": {"duration": 0.02222807999987708, "outcome": "passed"}, "call": {"duration": 0.006276667000065572, "outcome": "passed"}, "teardown": {"duration": 0.00031459899992114515, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022250141000085932, "outcome": "passed"}, "call": {"duration": 0.00587027799997486, "outcome": "passed"}, "teardown": {"duration": 0.0002262829998471716, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.022266580999939833, "outcome": "passed"}, "call": {"duration": 0.16543714200020077, "outcome": "passed"}, "teardown": {"duration": 0.000268041000026642, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.02332146499998089, "outcome": "passed"}, "call": {"duration": 0.09558298899992224, "outcome": "passed"}, "teardown": {"duration": 0.0002728599999954895, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.024376789999905668, "outcome": "passed"}, "call": {"duration": 0.1256744269999217, "outcome": "passed"}, "teardown": {"duration": 0.0002540359998874919, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_missing"}, "setup": {"duration": 0.023784793000004356, "outcome": "passed"}, "call": {"duration": 0.005495232999919608, "outcome": "passed"}, "teardown": {"duration": 0.0002252319998206076, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.023422124000035183, "outcome": "passed"}, "call": {"duration": 0.005865628000037759, "outcome": "passed"}, "teardown": {"duration": 0.00016704299991943117, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.022783367999863913, "outcome": "passed"}, "call": {"duration": 0.11694075400009751, "outcome": "passed"}, "teardown": {"duration": 0.0002787319999697502, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.03295035600012852, "outcome": "passed"}, "call": {"duration": 0.09771004999993238, "outcome": "passed"}, "teardown": {"duration": 0.0002586440000413859, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.024960873000054562, "outcome": "passed"}, "call": {"duration": 0.11730499200007216, "outcome": "passed"}, "teardown": {"duration": 0.0002798240000174701, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_missing"}, "setup": {"duration": 0.025432556000168915, "outcome": "passed"}, "call": {"duration": 0.006254991000105292, "outcome": "passed"}, "teardown": {"duration": 0.00023079199991116184, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022341021000102046, "outcome": "passed"}, "call": {"duration": 0.006089697000106753, "outcome": "passed"}, "teardown": {"duration": 0.0002559290001045156, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.022270528000035483, "outcome": "passed"}, "call": {"duration": 0.11658724800008713, "outcome": "passed"}, "teardown": {"duration": 0.00030635300004178134, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.022133020999945074, "outcome": "passed"}, "call": {"duration": 0.09563533499999721, "outcome": "passed"}, "teardown": {"duration": 0.0002413720001186448, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.022652903999869523, "outcome": "passed"}, "call": {"duration": 0.11809174600011829, "outcome": "passed"}, "teardown": {"duration": 0.0002777199999854929, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_missing"}, "setup": {"duration": 0.023139033000006748, "outcome": "passed"}, "call": {"duration": 0.00530506800009789, "outcome": "passed"}, "teardown": {"duration": 0.00019926300001316122, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022772538000026543, "outcome": "passed"}, "call": {"duration": 0.006220243999905506, "outcome": "passed"}, "teardown": {"duration": 0.0002776599999378959, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.02285194599994611, "outcome": "passed"}, "call": {"duration": 0.10077353499991659, "outcome": "passed"}, "teardown": {"duration": 0.00023868700009188615, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.0240437469999506, "outcome": "passed"}, "call": {"duration": 0.07962524799995663, "outcome": "passed"}, "teardown": {"duration": 0.0002738430000590597, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.023703960999910123, "outcome": "passed"}, "call": {"duration": 0.11157984900000883, "outcome": "passed"}, "teardown": {"duration": 0.00029590400004053663, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_missing"}, "setup": {"duration": 0.023647245000120165, "outcome": "passed"}, "call": {"duration": 0.005501019000121232, "outcome": "passed"}, "teardown": {"duration": 0.00028357099995446333, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.023508926000204156, "outcome": "passed"}, "call": {"duration": 0.006228385999975217, "outcome": "passed"}, "teardown": {"duration": 0.00023891799992270535, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.022241122999957952, "outcome": "passed"}, "call": {"duration": 0.09937084399984997, "outcome": "passed"}, "teardown": {"duration": 0.00020036499995512713, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.0249810709999565, "outcome": "passed"}, "call": {"duration": 0.07923527599996305, "outcome": "passed"}, "teardown": {"duration": 0.00020719799999824318, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.022800259999939954, "outcome": "passed"}, "call": {"duration": 0.10181801799990353, "outcome": "passed"}, "teardown": {"duration": 0.00027963399998043315, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_missing"}, "setup": {"duration": 0.022254641000017727, "outcome": "passed"}, "call": {"duration": 0.004891863000011654, "outcome": "passed"}, "teardown": {"duration": 0.00019497499988574418, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.021921136999935698, "outcome": "passed"}, "call": {"duration": 0.006265114999905563, "outcome": "passed"}, "teardown": {"duration": 0.0001927410000917007, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.02239030400005504, "outcome": "passed"}, "call": {"duration": 0.09960872800002107, "outcome": "passed"}, "teardown": {"duration": 0.0002787210000860796, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.024060950999910347, "outcome": "passed"}, "call": {"duration": 0.07801498599997103, "outcome": "passed"}, "teardown": {"duration": 0.0002263740000216785, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.023730963000161864, "outcome": "passed"}, "call": {"duration": 0.10002807699993355, "outcome": "passed"}, "teardown": {"duration": 0.00032205300021814764, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 133, "outcome": "skipped", "keywords": ["test_chat_non_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.024780838999959087, "outcome": "passed"}, "call": {"duration": 0.00014834700004939805, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 142, 'Skipped: Skipping test_chat_non_streaming_image for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00016426699994553928, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 133, "outcome": "passed", "keywords": ["test_chat_non_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.02907448500013743, "outcome": "passed"}, "call": {"duration": 0.9598593529999562, "outcome": "passed"}, "teardown": {"duration": 0.0002614000002267858, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 133, "outcome": "passed", "keywords": ["test_chat_non_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.022839243999897008, "outcome": "passed"}, "call": {"duration": 4.556547576999947, "outcome": "passed"}, "teardown": {"duration": 0.0002859660000922304, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 152, "outcome": "skipped", "keywords": ["test_chat_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.02301190800017139, "outcome": "passed"}, "call": {"duration": 0.0002427450001505349, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 161, 'Skipped: Skipping test_chat_streaming_image for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00016188300014619017, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 152, "outcome": "passed", "keywords": ["test_chat_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.021928591000005326, "outcome": "passed"}, "call": {"duration": 1.9934883710000122, "outcome": "passed"}, "teardown": {"duration": 0.0002405599998382968, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 152, "outcome": "passed", "keywords": ["test_chat_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.022573550000061005, "outcome": "passed"}, "call": {"duration": 4.654364419000103, "outcome": "passed"}, "teardown": {"duration": 0.00022376900005838252, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "calendar"}, "setup": {"duration": 0.02249905899998339, "outcome": "passed"}, "call": {"duration": 1.431310250000024, "outcome": "passed"}, "teardown": {"duration": 0.00025052899991351296, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "math"}, "setup": {"duration": 0.023177269000143497, "outcome": "passed"}, "call": {"duration": 3.2557497530001456, "outcome": "passed"}, "teardown": {"duration": 0.0002225069999894913, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "calendar"}, "setup": {"duration": 0.022710563000146067, "outcome": "passed"}, "call": {"duration": 0.4440871659999175, "outcome": "passed"}, "teardown": {"duration": 0.00022535200014317525, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "lineno": 176, "outcome": "failed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "math"}, "setup": {"duration": 0.022877594999954454, "outcome": "passed"}, "call": {"duration": 83.43984358600005, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 667, "message": "assert None is not None"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 197, "message": ""}, {"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 667, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]>>\nopenai_client = <openai.OpenAI object at 0x7f15112d3490>\nmodel = 'together/meta-llama/Llama-4-Scout-17B-16E-Instruct'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'math', 'input': {'messages': [{'content': 'You are a helpful math tutor. Guide the user through the solut... ['steps', 'final_answer'], 'title': 'MathReasoning', ...}}, 'type': 'json_schema'}}, 'output': 'valid_math_reasoning'}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_chat_structured_output\"][\"test_params\"][\"case\"],\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_structured_output(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        response = openai_client.chat.completions.create(\n            model=model,\n            messages=case[\"input\"][\"messages\"],\n            response_format=case[\"input\"][\"response_format\"],\n            stream=False,\n        )\n    \n        assert response.choices[0].message.role == \"assistant\"\n        maybe_json_content = response.choices[0].message.content\n    \n>       validate_structured_output(maybe_json_content, case[\"output\"])\n\ntests/verifications/openai_api/test_chat_completion.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nmaybe_json_content = '{  \\r\\n\\r\\n\\r\\n \\r\\n \\r\\n \\r\\n\\r\\n \\r\\n\\r\\n \\r\\n\\r\\n \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n \\r\\n\\r\\n \\r\\n\\r\\n \\r\\n\\r\\n \\r\\n\\r\\n\\r\\n\\r\\n... \\r\\n\\r\\n\\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n \\r\\n'\nschema_name = 'valid_math_reasoning'\n\n    def validate_structured_output(maybe_json_content: str, schema_name: str) -> None:\n        structured_output = get_structured_output(maybe_json_content, schema_name)\n>       assert structured_output is not None\nE       assert None is not None\n\ntests/verifications/openai_api/test_chat_completion.py:667: AssertionError"}, "teardown": {"duration": 0.0002560499999617605, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "calendar"}, "setup": {"duration": 0.02236130599999342, "outcome": "passed"}, "call": {"duration": 0.4991381239999555, "outcome": "passed"}, "teardown": {"duration": 0.00020139699995525007, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "math"}, "setup": {"duration": 0.022973471999875983, "outcome": "passed"}, "call": {"duration": 2.3270281630000227, "outcome": "passed"}, "teardown": {"duration": 0.0002398290000655834, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "calendar"}, "setup": {"duration": 0.022845670999913636, "outcome": "passed"}, "call": {"duration": 1.9240759110000454, "outcome": "passed"}, "teardown": {"duration": 0.0002788620001865638, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "math"}, "setup": {"duration": 0.02253192500006662, "outcome": "passed"}, "call": {"duration": 1.7501848130000326, "outcome": "passed"}, "teardown": {"duration": 0.00030855799991513777, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "calendar"}, "setup": {"duration": 0.022586314999898605, "outcome": "passed"}, "call": {"duration": 0.4860275500000171, "outcome": "passed"}, "teardown": {"duration": 0.0002566910000041389, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "math"}, "setup": {"duration": 0.022527115000002595, "outcome": "passed"}, "call": {"duration": 3.1515361480001047, "outcome": "passed"}, "teardown": {"duration": 0.00024493799992342247, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "calendar"}, "setup": {"duration": 0.029176744999858784, "outcome": "passed"}, "call": {"duration": 0.5592805280000448, "outcome": "passed"}, "teardown": {"duration": 0.00027150799996888964, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "math"}, "setup": {"duration": 0.02294886200002111, "outcome": "passed"}, "call": {"duration": 2.8789646660000017, "outcome": "passed"}, "teardown": {"duration": 0.00020196800005578552, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 221, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.022530960000040068, "outcome": "passed"}, "call": {"duration": 0.4420851450001919, "outcome": "passed"}, "teardown": {"duration": 0.0003113719999419118, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 221, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.023130754000021625, "outcome": "passed"}, "call": {"duration": 0.3291652200000499, "outcome": "passed"}, "teardown": {"duration": 0.00027332199988450157, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 221, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.022853854999993928, "outcome": "passed"}, "call": {"duration": 0.3279505309999422, "outcome": "passed"}, "teardown": {"duration": 0.00023072099997989426, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 245, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.022875645000112854, "outcome": "passed"}, "call": {"duration": 0.9116010949999236, "outcome": "passed"}, "teardown": {"duration": 0.0002237290000266512, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 245, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.023123509000015474, "outcome": "passed"}, "call": {"duration": 0.3074044300001333, "outcome": "passed"}, "teardown": {"duration": 0.00031364699998448486, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 245, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.022965694000049552, "outcome": "passed"}, "call": {"duration": 0.6460213779998867, "outcome": "passed"}, "teardown": {"duration": 0.00022208599989426148, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 273, "outcome": "failed", "keywords": ["test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.023541372000181582, "outcome": "passed"}, "call": {"duration": 0.8061084040000424, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 1023, "message": "openai.BadRequestError: Error code: 400 - {'detail': \"Error code: 400 - {'id': 'nu3MUsC-3NKUce-93fc8df0d865113a', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}\"}"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 284, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_utils/_utils.py", "lineno": 279, "message": "in wrapper"}, {"path": ".venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", "lineno": 914, "message": "in create"}, {"path": ".venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 1242, "message": "in post"}, {"path": ".venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 919, "message": "in request"}, {"path": ".venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 1023, "message": "BadRequestError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]>>\nopenai_client = <openai.OpenAI object at 0x7f15111ebc10>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'input': {'messages': [{'content': 'You are a helpful assistant that can use tools to get information.', 'role': 'sys..., 'properties': {...}, 'required': [...], 'type': 'object'}}, 'type': 'function'}]}, 'output': 'get_weather_tool_call'}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_tool_calling\"][\"test_params\"][\"case\"],  # Reusing existing case for now\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_tool_choice_required(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n>       response = openai_client.chat.completions.create(\n            model=model,\n            messages=case[\"input\"][\"messages\"],\n            tools=case[\"input\"][\"tools\"],\n            tool_choice=\"required\",  # Force tool call\n            stream=False,\n        )\n\ntests/verifications/openai_api/test_chat_completion.py:284: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:279: in wrapper\n    return func(*args, **kwargs)\n.venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914: in create\n    return self._post(\n.venv/lib/python3.10/site-packages/openai/_base_client.py:1242: in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n.venv/lib/python3.10/site-packages/openai/_base_client.py:919: in request\n    return self._request(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <openai.OpenAI object at 0x7f15111ebc10>\n\n    def _request(\n        self,\n        *,\n        cast_to: Type[ResponseT],\n        options: FinalRequestOptions,\n        retries_taken: int,\n        stream: bool,\n        stream_cls: type[_StreamT] | None,\n    ) -> ResponseT | _StreamT:\n        # create a copy of the options we were given so that if the\n        # options are mutated later & we then retry, the retries are\n        # given the original options\n        input_options = model_copy(options)\n    \n        cast_to = self._maybe_override_cast_to(cast_to, options)\n        options = self._prepare_options(options)\n    \n        remaining_retries = options.get_max_retries(self.max_retries) - retries_taken\n        request = self._build_request(options, retries_taken=retries_taken)\n        self._prepare_request(request)\n    \n        kwargs: HttpxSendArgs = {}\n        if self.custom_auth is not None:\n            kwargs[\"auth\"] = self.custom_auth\n    \n        log.debug(\"Sending HTTP Request: %s %s\", request.method, request.url)\n    \n        try:\n            response = self._client.send(\n                request,\n                stream=stream or self._should_stream_response_body(request=request),\n                **kwargs,\n            )\n        except httpx.TimeoutException as err:\n            log.debug(\"Encountered httpx.TimeoutException\", exc_info=True)\n    \n            if remaining_retries > 0:\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising timeout error\")\n            raise APITimeoutError(request=request) from err\n        except Exception as err:\n            log.debug(\"Encountered Exception\", exc_info=True)\n    \n            if remaining_retries > 0:\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising connection error\")\n            raise APIConnectionError(request=request) from err\n    \n        log.debug(\n            'HTTP Response: %s %s \"%i %s\" %s',\n            request.method,\n            request.url,\n            response.status_code,\n            response.reason_phrase,\n            response.headers,\n        )\n        log.debug(\"request_id: %s\", response.headers.get(\"x-request-id\"))\n    \n        try:\n            response.raise_for_status()\n        except httpx.HTTPStatusError as err:  # thrown on 4xx and 5xx status code\n            log.debug(\"Encountered httpx.HTTPStatusError\", exc_info=True)\n    \n            if remaining_retries > 0 and self._should_retry(err.response):\n                err.response.close()\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    response_headers=err.response.headers,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                )\n    \n            # If the response is streamed then we need to explicitly read the response\n            # to completion before attempting to access the response text.\n            if not err.response.is_closed:\n                err.response.read()\n    \n            log.debug(\"Re-raising status error\")\n>           raise self._make_status_error_from_response(err.response) from None\nE           openai.BadRequestError: Error code: 400 - {'detail': \"Error code: 400 - {'id': 'nu3MUsC-3NKUce-93fc8df0d865113a', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}\"}\n\n.venv/lib/python3.10/site-packages/openai/_base_client.py:1023: BadRequestError"}, "teardown": {"duration": 0.0002803849999963859, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 273, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.02270072800001799, "outcome": "passed"}, "call": {"duration": 0.3615173910000067, "outcome": "passed"}, "teardown": {"duration": 0.0003068739999889658, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 273, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.023169965000079173, "outcome": "passed"}, "call": {"duration": 0.6361196039999868, "outcome": "passed"}, "teardown": {"duration": 0.00022088300011091633, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 297, "outcome": "failed", "keywords": ["test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.023880145000021002, "outcome": "passed"}, "call": {"duration": 0.5136475489998702, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 72, "message": "openai.APIError: 400: Error code: 400 - {'id': 'nu3MVTr-3NKUce-93fc8dfd6fed113a', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 316, "message": ""}, {"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 682, "message": "in _accumulate_streaming_tool_calls"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 72, "message": "APIError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]>>\nopenai_client = <openai.OpenAI object at 0x7f1511218550>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'input': {'messages': [{'content': 'You are a helpful assistant that can use tools to get information.', 'role': 'sys..., 'properties': {...}, 'required': [...], 'type': 'object'}}, 'type': 'function'}]}, 'output': 'get_weather_tool_call'}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_tool_calling\"][\"test_params\"][\"case\"],  # Reusing existing case for now\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_tool_choice_required(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        stream = openai_client.chat.completions.create(\n            model=model,\n            messages=case[\"input\"][\"messages\"],\n            tools=case[\"input\"][\"tools\"],\n            tool_choice=\"required\",  # Force tool call\n            stream=True,\n        )\n    \n>       _, tool_calls_buffer = _accumulate_streaming_tool_calls(stream)\n\ntests/verifications/openai_api/test_chat_completion.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/verifications/openai_api/test_chat_completion.py:682: in _accumulate_streaming_tool_calls\n    for chunk in stream:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <openai.Stream object at 0x7f15113a71f0>\n\n    def __stream__(self) -> Iterator[_T]:\n        cast_to = cast(Any, self._cast_to)\n        response = self.response\n        process_data = self._client._process_response_data\n        iterator = self._iter_events()\n    \n        for sse in iterator:\n            if sse.data.startswith(\"[DONE]\"):\n                break\n    \n            if sse.event is None or sse.event.startswith(\"response.\") or sse.event.startswith('transcript.'):\n                data = sse.json()\n                if is_mapping(data) and data.get(\"error\"):\n                    message = None\n                    error = data.get(\"error\")\n                    if is_mapping(error):\n                        message = error.get(\"message\")\n                    if not message or not isinstance(message, str):\n                        message = \"An error occurred during streaming\"\n    \n>                   raise APIError(\n                        message=message,\n                        request=self.response.request,\n                        body=data[\"error\"],\n                    )\nE                   openai.APIError: 400: Error code: 400 - {'id': 'nu3MVTr-3NKUce-93fc8dfd6fed113a', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}\n\n.venv/lib/python3.10/site-packages/openai/_streaming.py:72: APIError"}, "teardown": {"duration": 0.0002596970000467991, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 297, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.022556669000096008, "outcome": "passed"}, "call": {"duration": 0.3859737300001598, "outcome": "passed"}, "teardown": {"duration": 0.00035947199990005174, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 297, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.02258860899996762, "outcome": "passed"}, "call": {"duration": 0.7068651009999485, "outcome": "passed"}, "teardown": {"duration": 0.00022332699995786243, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 324, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.023002702999974645, "outcome": "passed"}, "call": {"duration": 6.739836890000106, "outcome": "passed"}, "teardown": {"duration": 0.00027515400006450363, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 324, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.02610660999994252, "outcome": "passed"}, "call": {"duration": 5.065787258, "outcome": "passed"}, "teardown": {"duration": 0.0002606979999200121, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 324, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.023932111000021905, "outcome": "passed"}, "call": {"duration": 1.5769547659999716, "outcome": "passed"}, "teardown": {"duration": 0.00025717099993016745, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.023815424000076746, "outcome": "passed"}, "call": {"duration": 2.5521993600000314, "outcome": "passed"}, "teardown": {"duration": 0.00021323900000425056, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.022321538000142027, "outcome": "passed"}, "call": {"duration": 5.225448257999915, "outcome": "passed"}, "teardown": {"duration": 0.00026037799989353516, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.02261009699986971, "outcome": "passed"}, "call": {"duration": 0.5641777890000412, "outcome": "passed"}, "teardown": {"duration": 0.00023531000010734715, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "lineno": 375, "outcome": "failed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022393942000007883, "outcome": "passed"}, "call": {"duration": 0.35859038799981136, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 434, "message": "AssertionError: Expected 0 tool calls, but got 1\nassert 1 == 0\n +  where 1 = len(([ChatCompletionMessageToolCall(id='call_rjje2bun6gte86udvqnfww8z', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]))\n +    where [ChatCompletionMessageToolCall(id='call_rjje2bun6gte86udvqnfww8z', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)] = ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rjje2bun6gte86udvqnfww8z', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]).tool_calls"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 434, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f151128ee60>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\"\n        Test cases for multi-turn tool calling.\n        Tool calls are asserted.\n        Tool responses are provided in the test case.\n        Final response is asserted.\n        \"\"\"\n    \n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        # Create a copy of the messages list to avoid modifying the original\n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        # Use deepcopy to prevent modification across runs/parametrization\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        # keep going until either\n        # 1. we have messages to test in multi-turn\n        # 2. no messages but last message is tool response\n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            # do not take new messages if last message is tool response\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                # Ensure new_messages is a list of message objects\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    # If it's a single message object, add it directly\n                    messages.append(new_messages)\n    \n            # --- API Call ---\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=False,\n            )\n    \n            # --- Process Response ---\n            assistant_message = response.choices[0].message\n            messages.append(assistant_message.model_dump(exclude_unset=True))\n    \n            assert assistant_message.role == \"assistant\"\n    \n            # Get the expected result data\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n            # --- Assertions based on expected result ---\n>           assert len(assistant_message.tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(assistant_message.tool_calls or [])}\"\n            )\nE           AssertionError: Expected 0 tool calls, but got 1\nE           assert 1 == 0\nE            +  where 1 = len(([ChatCompletionMessageToolCall(id='call_rjje2bun6gte86udvqnfww8z', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]))\nE            +    where [ChatCompletionMessageToolCall(id='call_rjje2bun6gte86udvqnfww8z', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)] = ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rjje2bun6gte86udvqnfww8z', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]).tool_calls\n\ntests/verifications/openai_api/test_chat_completion.py:434: AssertionError"}, "teardown": {"duration": 0.0002285959999426268, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.022510065000005852, "outcome": "passed"}, "call": {"duration": 1.7667226409998875, "outcome": "passed"}, "teardown": {"duration": 0.0002465919999394828, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "add_product_tool"}, "setup": {"duration": 0.02289034000000356, "outcome": "passed"}, "call": {"duration": 2.4364398529999107, "outcome": "passed"}, "teardown": {"duration": 0.00023173399995357613, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.023599795999871276, "outcome": "passed"}, "call": {"duration": 2.6509406049999598, "outcome": "passed"}, "teardown": {"duration": 0.00024348600004486798, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.023555012000088027, "outcome": "passed"}, "call": {"duration": 1.4720750989999942, "outcome": "passed"}, "teardown": {"duration": 0.00021302799996192334, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "lineno": 375, "outcome": "failed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.023459797999976217, "outcome": "passed"}, "call": {"duration": 0.35168141100007233, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 462, "message": "AssertionError: Expected one of ['sol'] in content, but got: 'I am not able to complete this task as it falls outside of the scope of the functions I have been given.'\nassert False\n +  where False = any(<generator object test_chat_non_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f151118f530>)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 462, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f1511397760>\nmodel = 'together/meta-llama/Llama-4-Scout-17B-16E-Instruct'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\"\n        Test cases for multi-turn tool calling.\n        Tool calls are asserted.\n        Tool responses are provided in the test case.\n        Final response is asserted.\n        \"\"\"\n    \n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        # Create a copy of the messages list to avoid modifying the original\n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        # Use deepcopy to prevent modification across runs/parametrization\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        # keep going until either\n        # 1. we have messages to test in multi-turn\n        # 2. no messages but last message is tool response\n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            # do not take new messages if last message is tool response\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                # Ensure new_messages is a list of message objects\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    # If it's a single message object, add it directly\n                    messages.append(new_messages)\n    \n            # --- API Call ---\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=False,\n            )\n    \n            # --- Process Response ---\n            assistant_message = response.choices[0].message\n            messages.append(assistant_message.model_dump(exclude_unset=True))\n    \n            assert assistant_message.role == \"assistant\"\n    \n            # Get the expected result data\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n            # --- Assertions based on expected result ---\n            assert len(assistant_message.tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(assistant_message.tool_calls or [])}\"\n            )\n    \n            if num_tool_calls > 0:\n                tool_call = assistant_message.tool_calls[0]\n                assert tool_call.function.name == expected[\"tool_name\"], (\n                    f\"Expected tool '{expected['tool_name']}', got '{tool_call.function.name}'\"\n                )\n                # Parse the JSON string arguments before comparing\n                actual_arguments = json.loads(tool_call.function.arguments)\n                assert actual_arguments == expected[\"tool_arguments\"], (\n                    f\"Expected arguments '{expected['tool_arguments']}', got '{actual_arguments}'\"\n                )\n    \n                # Prepare and append the tool response for the next turn\n                tool_response = tool_responses.pop(0)\n                messages.append(\n                    {\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call.id,\n                        \"content\": tool_response[\"response\"],\n                    }\n                )\n            else:\n                assert assistant_message.content is not None, \"Expected content, but none received.\"\n                expected_answers = expected[\"answer\"]  # This is now a list\n                content_lower = assistant_message.content.lower()\n>               assert any(ans.lower() in content_lower for ans in expected_answers), (\n                    f\"Expected one of {expected_answers} in content, but got: '{assistant_message.content}'\"\n                )\nE               AssertionError: Expected one of ['sol'] in content, but got: 'I am not able to complete this task as it falls outside of the scope of the functions I have been given.'\nE               assert False\nE                +  where False = any(<generator object test_chat_non_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f151118f530>)\n\ntests/verifications/openai_api/test_chat_completion.py:462: AssertionError"}, "teardown": {"duration": 0.00018707000003814755, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.022372585000084655, "outcome": "passed"}, "call": {"duration": 0.5493874199999027, "outcome": "passed"}, "teardown": {"duration": 0.00020656599986068613, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "add_product_tool"}, "setup": {"duration": 0.02240999500008911, "outcome": "passed"}, "call": {"duration": 0.6900100750001457, "outcome": "passed"}, "teardown": {"duration": 0.00022725500002707122, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.023061642999891774, "outcome": "passed"}, "call": {"duration": 1.6639151179999772, "outcome": "passed"}, "teardown": {"duration": 0.00024112999994940765, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.023736064000104307, "outcome": "passed"}, "call": {"duration": 1.334252848999995, "outcome": "passed"}, "teardown": {"duration": 0.00023183400003290444, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022719969000036144, "outcome": "passed"}, "call": {"duration": 2.198282335000158, "outcome": "passed"}, "teardown": {"duration": 0.0002388969999174151, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.023483993000127157, "outcome": "passed"}, "call": {"duration": 0.6698950980000973, "outcome": "passed"}, "teardown": {"duration": 0.0002944400000615133, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "add_product_tool"}, "setup": {"duration": 0.022567406000007395, "outcome": "passed"}, "call": {"duration": 1.0168574020001415, "outcome": "passed"}, "teardown": {"duration": 0.00025905400002557144, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.02260122899997441, "outcome": "passed"}, "call": {"duration": 1.9930232619999515, "outcome": "passed"}, "teardown": {"duration": 0.0003381930000614375, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.023052540999970006, "outcome": "passed"}, "call": {"duration": 1.784074068000109, "outcome": "passed"}, "teardown": {"duration": 0.00028380099979585793, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "lineno": 466, "outcome": "failed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022602787999858265, "outcome": "passed"}, "call": {"duration": 0.5541614619999109, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError: Expected 0 tool calls, but got 1\nassert 1 == 0\n +  where 1 = len(([{'function': {'arguments': '{\"location\":\"San Francisco, CA\"}', 'name': 'get_weather'}, 'id': 'call_1bfzy9wbd1en7l3259gs7hg0', 'type': 'function'}]))"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f15113ba0b0>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\" \"\"\"\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    messages.append(new_messages)\n    \n            # --- API Call (Streaming) ---\n            stream = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n    \n            # --- Process Stream ---\n            accumulated_content, accumulated_tool_calls = _accumulate_streaming_tool_calls(stream)\n    \n            # --- Construct Assistant Message for History ---\n            assistant_message_dict = {\"role\": \"assistant\"}\n            if accumulated_content:\n                assistant_message_dict[\"content\"] = accumulated_content\n            if accumulated_tool_calls:\n                assistant_message_dict[\"tool_calls\"] = accumulated_tool_calls\n    \n            messages.append(assistant_message_dict)\n    \n            # --- Assertions ---\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n>           assert len(accumulated_tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(accumulated_tool_calls or [])}\"\n            )\nE           AssertionError: Expected 0 tool calls, but got 1\nE           assert 1 == 0\nE            +  where 1 = len(([{'function': {'arguments': '{\"location\":\"San Francisco, CA\"}', 'name': 'get_weather'}, 'id': 'call_1bfzy9wbd1en7l3259gs7hg0', 'type': 'function'}]))\n\ntests/verifications/openai_api/test_chat_completion.py:516: AssertionError"}, "teardown": {"duration": 0.00019849099999191822, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.022153468999931647, "outcome": "passed"}, "call": {"duration": 0.9443487239998376, "outcome": "passed"}, "teardown": {"duration": 0.00019619600016085315, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "add_product_tool"}, "setup": {"duration": 0.022840404000135095, "outcome": "passed"}, "call": {"duration": 5.651675383000111, "outcome": "passed"}, "teardown": {"duration": 0.000253934999818739, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022273972999983016, "outcome": "passed"}, "call": {"duration": 2.6258857759999046, "outcome": "passed"}, "teardown": {"duration": 0.0002575210000941297, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022439537000082055, "outcome": "passed"}, "call": {"duration": 2.8875541659999726, "outcome": "passed"}, "teardown": {"duration": 0.00022103299988884828, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "lineno": 466, "outcome": "failed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.02250982300006399, "outcome": "passed"}, "call": {"duration": 2.129944791999833, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError: Expected 0 tool calls, but got 1\nassert 1 == 0\n +  where 1 = len(([{'function': {'arguments': '{\"location\":\"Sun, Latin\"}', 'name': 'get_weather'}, 'id': 'call_xywx2sivzppzv78f5mrilyum', 'type': 'function'}]))"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f1511274370>\nmodel = 'together/meta-llama/Llama-4-Scout-17B-16E-Instruct'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\" \"\"\"\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    messages.append(new_messages)\n    \n            # --- API Call (Streaming) ---\n            stream = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n    \n            # --- Process Stream ---\n            accumulated_content, accumulated_tool_calls = _accumulate_streaming_tool_calls(stream)\n    \n            # --- Construct Assistant Message for History ---\n            assistant_message_dict = {\"role\": \"assistant\"}\n            if accumulated_content:\n                assistant_message_dict[\"content\"] = accumulated_content\n            if accumulated_tool_calls:\n                assistant_message_dict[\"tool_calls\"] = accumulated_tool_calls\n    \n            messages.append(assistant_message_dict)\n    \n            # --- Assertions ---\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n>           assert len(accumulated_tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(accumulated_tool_calls or [])}\"\n            )\nE           AssertionError: Expected 0 tool calls, but got 1\nE           assert 1 == 0\nE            +  where 1 = len(([{'function': {'arguments': '{\"location\":\"Sun, Latin\"}', 'name': 'get_weather'}, 'id': 'call_xywx2sivzppzv78f5mrilyum', 'type': 'function'}]))\n\ntests/verifications/openai_api/test_chat_completion.py:516: AssertionError"}, "teardown": {"duration": 0.00021496199997272925, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.02212973099994997, "outcome": "passed"}, "call": {"duration": 0.8185512420000123, "outcome": "passed"}, "teardown": {"duration": 0.00022502100000565406, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "lineno": 466, "outcome": "failed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "add_product_tool"}, "setup": {"duration": 0.02300152199995864, "outcome": "passed"}, "call": {"duration": 1.3437507860001006, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError: Expected 0 tool calls, but got 1\nassert 1 == 0\n +  where 1 = len(([{'function': {'arguments': '{\"inStock\":true,\"name\":\"Widget\",\"price\":19.99,\"tags\":[\"new\",\"sale\"]}', 'name': 'addProduct'}, 'id': 'call_9lqityrco8l00j81vrla44yz', 'type': 'function'}]))"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f15110f1480>\nmodel = 'together/meta-llama/Llama-4-Scout-17B-16E-Instruct'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'add_product_tool', 'expected': [{'num_tool_calls': 1, 'tool_arguments': {'inStock': True, 'name': 'Widget...}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': 'Successfully added product with id: 123'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\" \"\"\"\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    messages.append(new_messages)\n    \n            # --- API Call (Streaming) ---\n            stream = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n    \n            # --- Process Stream ---\n            accumulated_content, accumulated_tool_calls = _accumulate_streaming_tool_calls(stream)\n    \n            # --- Construct Assistant Message for History ---\n            assistant_message_dict = {\"role\": \"assistant\"}\n            if accumulated_content:\n                assistant_message_dict[\"content\"] = accumulated_content\n            if accumulated_tool_calls:\n                assistant_message_dict[\"tool_calls\"] = accumulated_tool_calls\n    \n            messages.append(assistant_message_dict)\n    \n            # --- Assertions ---\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n>           assert len(accumulated_tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(accumulated_tool_calls or [])}\"\n            )\nE           AssertionError: Expected 0 tool calls, but got 1\nE           assert 1 == 0\nE            +  where 1 = len(([{'function': {'arguments': '{\"inStock\":true,\"name\":\"Widget\",\"price\":19.99,\"tags\":[\"new\",\"sale\"]}', 'name': 'addProduct'}, 'id': 'call_9lqityrco8l00j81vrla44yz', 'type': 'function'}]))\n\ntests/verifications/openai_api/test_chat_completion.py:516: AssertionError"}, "teardown": {"duration": 0.00024335499983862974, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022341186999938145, "outcome": "passed"}, "call": {"duration": 1.879501277999907, "outcome": "passed"}, "teardown": {"duration": 0.00020251800015103072, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022583315000019866, "outcome": "passed"}, "call": {"duration": 1.501675664000004, "outcome": "passed"}, "teardown": {"duration": 0.0003406570001516229, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "lineno": 466, "outcome": "failed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022211730999970314, "outcome": "passed"}, "call": {"duration": 0.39965771500010305, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 545, "message": "AssertionError: Expected one of ['sol'] in content, but got: '{\"name\": null, \"parameters\": null}'\nassert False\n +  where False = any(<generator object test_chat_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f1511092730>)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 545, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f15110d06a0>\nmodel = 'together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\" \"\"\"\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    messages.append(new_messages)\n    \n            # --- API Call (Streaming) ---\n            stream = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n    \n            # --- Process Stream ---\n            accumulated_content, accumulated_tool_calls = _accumulate_streaming_tool_calls(stream)\n    \n            # --- Construct Assistant Message for History ---\n            assistant_message_dict = {\"role\": \"assistant\"}\n            if accumulated_content:\n                assistant_message_dict[\"content\"] = accumulated_content\n            if accumulated_tool_calls:\n                assistant_message_dict[\"tool_calls\"] = accumulated_tool_calls\n    \n            messages.append(assistant_message_dict)\n    \n            # --- Assertions ---\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n            assert len(accumulated_tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(accumulated_tool_calls or [])}\"\n            )\n    \n            if num_tool_calls > 0:\n                # Use the first accumulated tool call for assertion\n                tool_call = accumulated_tool_calls[0]\n                assert tool_call[\"function\"][\"name\"] == expected[\"tool_name\"], (\n                    f\"Expected tool '{expected['tool_name']}', got '{tool_call['function']['name']}'\"\n                )\n                # Parse the accumulated arguments string for comparison\n                actual_arguments = json.loads(tool_call[\"function\"][\"arguments\"])\n                assert actual_arguments == expected[\"tool_arguments\"], (\n                    f\"Expected arguments '{expected['tool_arguments']}', got '{actual_arguments}'\"\n                )\n    \n                # Prepare and append the tool response for the next turn\n                tool_response = tool_responses.pop(0)\n                messages.append(\n                    {\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call[\"id\"],\n                        \"content\": tool_response[\"response\"],\n                    }\n                )\n            else:\n                assert accumulated_content is not None and accumulated_content != \"\", \"Expected content, but none received.\"\n                expected_answers = expected[\"answer\"]\n                content_lower = accumulated_content.lower()\n>               assert any(ans.lower() in content_lower for ans in expected_answers), (\n                    f\"Expected one of {expected_answers} in content, but got: '{accumulated_content}'\"\n                )\nE               AssertionError: Expected one of ['sol'] in content, but got: '{\"name\": null, \"parameters\": null}'\nE               assert False\nE                +  where False = any(<generator object test_chat_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f1511092730>)\n\ntests/verifications/openai_api/test_chat_completion.py:545: AssertionError"}, "teardown": {"duration": 0.0001878309999483463, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.02207242999998016, "outcome": "passed"}, "call": {"duration": 0.8109623320001447, "outcome": "passed"}, "teardown": {"duration": 0.00022341800013236934, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "add_product_tool"}, "setup": {"duration": 0.022401604999913616, "outcome": "passed"}, "call": {"duration": 1.1644620600000053, "outcome": "passed"}, "teardown": {"duration": 0.0002801129999170371, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.02225455999996484, "outcome": "passed"}, "call": {"duration": 2.107342147000054, "outcome": "passed"}, "teardown": {"duration": 0.00024722299986024154, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.02241852699989977, "outcome": "passed"}, "call": {"duration": 1.8361532680000892, "outcome": "passed"}, "teardown": {"duration": 0.0003065429998514446, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False]", "lineno": 549, "outcome": "skipped", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "stream=False"}, "setup": {"duration": 0.02303772699997353, "outcome": "passed"}, "call": {"duration": 0.00017660100002103718, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 556, 'Skipped: Skipping test_chat_multi_turn_multiple_images for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00017079899998861947, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True]", "lineno": 549, "outcome": "skipped", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "stream=True"}, "setup": {"duration": 0.022561777000191796, "outcome": "passed"}, "call": {"duration": 0.00023316600004363863, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 556, 'Skipped: Skipping test_chat_multi_turn_multiple_images for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00018829200007530744, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "stream=False"}, "setup": {"duration": 0.02255651699988448, "outcome": "passed"}, "call": {"duration": 3.7836474639998414, "outcome": "passed"}, "teardown": {"duration": 0.0002188089999890508, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "stream=True"}, "setup": {"duration": 0.023786447000020416, "outcome": "passed"}, "call": {"duration": 3.882159505000118, "outcome": "passed"}, "teardown": {"duration": 0.0002505480001673277, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "stream=False"}, "setup": {"duration": 0.023196804000008342, "outcome": "passed"}, "call": {"duration": 3.6701133429999118, "outcome": "passed"}, "teardown": {"duration": 0.0002176969999254652, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "stream=True"}, "setup": {"duration": 0.023491619999958857, "outcome": "passed"}, "call": {"duration": 3.284086521000063, "outcome": "passed"}, "teardown": {"duration": 0.0027315180000186956, "outcome": "passed"}}]}