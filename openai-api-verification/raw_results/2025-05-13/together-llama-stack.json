{"created": 1747102620.2495832, "duration": 128.97946429252625, "exitcode": 1, "root": "/home/runner/work/llama-stack-tests/llama-stack-tests", "environment": {}, "summary": {"passed": 102, "skipped": 4, "failed": 8, "total": 114, "collected": 114}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py", "type": "Module"}]}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py", "outcome": "passed", "result": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "type": "Function", "lineno": 46}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "type": "Function", "lineno": 65}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "type": "Function", "lineno": 89}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "type": "Function", "lineno": 110}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 133}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 133}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 133}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 152}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 152}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 152}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "type": "Function", "lineno": 176}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "type": "Function", "lineno": 199}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 221}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 221}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 221}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 245}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 245}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 245}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 273}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 273}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 273}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 297}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 297}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 297}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 324}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 324}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 324}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "type": "Function", "lineno": 347}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "type": "Function", "lineno": 375}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "type": "Function", "lineno": 466}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False]", "type": "Function", "lineno": 549}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True]", "type": "Function", "lineno": 549}]}], "tests": [{"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "earth"}, "setup": {"duration": 0.05489226600002439, "outcome": "passed"}, "call": {"duration": 0.5885075180000285, "outcome": "passed"}, "teardown": {"duration": 0.0002456489999076439, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "saturn"}, "setup": {"duration": 0.022959105999916574, "outcome": "passed"}, "call": {"duration": 0.5098926069999834, "outcome": "passed"}, "teardown": {"duration": 0.0003628279999929873, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "earth"}, "setup": {"duration": 0.023755444000016723, "outcome": "passed"}, "call": {"duration": 0.7764416759999904, "outcome": "passed"}, "teardown": {"duration": 0.00032693100001779385, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "saturn"}, "setup": {"duration": 0.02384337000000869, "outcome": "passed"}, "call": {"duration": 0.4628900249999788, "outcome": "passed"}, "teardown": {"duration": 0.0002100120000250172, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "earth"}, "setup": {"duration": 0.023708184999918558, "outcome": "passed"}, "call": {"duration": 0.7255007780000824, "outcome": "passed"}, "teardown": {"duration": 0.000353571000005104, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "lineno": 46, "outcome": "passed", "keywords": ["test_chat_non_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "saturn"}, "setup": {"duration": 0.023995542999955433, "outcome": "passed"}, "call": {"duration": 0.7491929730000493, "outcome": "passed"}, "teardown": {"duration": 0.00022681400002966257, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "earth"}, "setup": {"duration": 0.02316977999998926, "outcome": "passed"}, "call": {"duration": 0.31561780099991665, "outcome": "passed"}, "teardown": {"duration": 0.00025261200005388673, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "saturn"}, "setup": {"duration": 0.023112031999971805, "outcome": "passed"}, "call": {"duration": 1.0528675040000053, "outcome": "passed"}, "teardown": {"duration": 0.0002183579999837093, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "earth"}, "setup": {"duration": 0.023066044999950464, "outcome": "passed"}, "call": {"duration": 0.8342347529999188, "outcome": "passed"}, "teardown": {"duration": 0.00020935200006988453, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "saturn"}, "setup": {"duration": 0.022535789000016848, "outcome": "passed"}, "call": {"duration": 0.6258328640000173, "outcome": "passed"}, "teardown": {"duration": 0.00021147600000404054, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-earth", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "earth"}, "setup": {"duration": 0.02216312200005177, "outcome": "passed"}, "call": {"duration": 0.7766486749999331, "outcome": "passed"}, "teardown": {"duration": 0.00021330800007035577, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "lineno": 65, "outcome": "passed", "keywords": ["test_chat_streaming_basic[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-saturn", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "saturn"}, "setup": {"duration": 0.022043437999968774, "outcome": "passed"}, "call": {"duration": 0.5946089810000785, "outcome": "passed"}, "teardown": {"duration": 0.00021408999998584477, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_missing"}, "setup": {"duration": 0.02190347600003406, "outcome": "passed"}, "call": {"duration": 0.006325552000021162, "outcome": "passed"}, "teardown": {"duration": 0.00023909599997296027, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.021881575000065823, "outcome": "passed"}, "call": {"duration": 0.006160004999969715, "outcome": "passed"}, "teardown": {"duration": 0.0001985220000051413, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.022274209999977757, "outcome": "passed"}, "call": {"duration": 0.301174154000023, "outcome": "passed"}, "teardown": {"duration": 0.00030171399998835113, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.022462160000031872, "outcome": "passed"}, "call": {"duration": 0.09675818899995647, "outcome": "passed"}, "teardown": {"duration": 0.00036456099996939884, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.0233544879999954, "outcome": "passed"}, "call": {"duration": 0.12879818399994747, "outcome": "passed"}, "teardown": {"duration": 0.0002932279999185994, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_missing"}, "setup": {"duration": 0.025340529999994033, "outcome": "passed"}, "call": {"duration": 0.006151076000037392, "outcome": "passed"}, "teardown": {"duration": 0.0002720279999266495, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.023282954000023892, "outcome": "passed"}, "call": {"duration": 0.006045109999945453, "outcome": "passed"}, "teardown": {"duration": 0.000310680999973556, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.02287360900004387, "outcome": "passed"}, "call": {"duration": 0.12920187099996383, "outcome": "passed"}, "teardown": {"duration": 0.0002979769999456039, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.024350309999931596, "outcome": "passed"}, "call": {"duration": 0.095052958999986, "outcome": "passed"}, "teardown": {"duration": 0.00030604200003381266, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.023036814999954913, "outcome": "passed"}, "call": {"duration": 0.11683738299996094, "outcome": "passed"}, "teardown": {"duration": 0.00023493899993809464, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_missing"}, "setup": {"duration": 0.022282454999981383, "outcome": "passed"}, "call": {"duration": 0.006422963999966669, "outcome": "passed"}, "teardown": {"duration": 0.00023943799999415205, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.0224865459999819, "outcome": "passed"}, "call": {"duration": 0.006561562999991111, "outcome": "passed"}, "teardown": {"duration": 0.00020865999999841733, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.021834678000004715, "outcome": "passed"}, "call": {"duration": 0.11651447899998857, "outcome": "passed"}, "teardown": {"duration": 0.00019199899998056935, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.02211064300001908, "outcome": "passed"}, "call": {"duration": 0.09449324999991404, "outcome": "passed"}, "teardown": {"duration": 0.0002603760000283728, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "lineno": 89, "outcome": "passed", "keywords": ["test_chat_non_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.022315978000051473, "outcome": "passed"}, "call": {"duration": 0.12038145899998653, "outcome": "passed"}, "teardown": {"duration": 0.00023353599999609287, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_missing"}, "setup": {"duration": 0.022165636000067934, "outcome": "passed"}, "call": {"duration": 0.005933379999987665, "outcome": "passed"}, "teardown": {"duration": 0.000273751000008815, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.023436811999999918, "outcome": "passed"}, "call": {"duration": 0.006554091999987577, "outcome": "passed"}, "teardown": {"duration": 0.0003946079999650465, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.021860937000042213, "outcome": "passed"}, "call": {"duration": 0.10463033599990013, "outcome": "passed"}, "teardown": {"duration": 0.0003253880000784193, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.024282883999944715, "outcome": "passed"}, "call": {"duration": 0.09138980200009428, "outcome": "passed"}, "teardown": {"duration": 0.00019433300008131482, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.022393071000010423, "outcome": "passed"}, "call": {"duration": 0.1045561529999759, "outcome": "passed"}, "teardown": {"duration": 0.0002227569999604384, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_missing"}, "setup": {"duration": 0.02251378799996928, "outcome": "passed"}, "call": {"duration": 0.006076672000062899, "outcome": "passed"}, "teardown": {"duration": 0.00018405399998755456, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022726383999952304, "outcome": "passed"}, "call": {"duration": 0.006875983999975688, "outcome": "passed"}, "teardown": {"duration": 0.00025589899996703025, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.022551447999944685, "outcome": "passed"}, "call": {"duration": 0.10531921599999805, "outcome": "passed"}, "teardown": {"duration": 0.00025251200008824526, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.022953017999952863, "outcome": "passed"}, "call": {"duration": 0.08421347800003787, "outcome": "passed"}, "teardown": {"duration": 0.0003352569999606203, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.023442303000024367, "outcome": "passed"}, "call": {"duration": 0.1077636470000698, "outcome": "passed"}, "teardown": {"duration": 0.0003524480000578478, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_missing", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_missing"}, "setup": {"duration": 0.02272425099999964, "outcome": "passed"}, "call": {"duration": 0.006272716000012224, "outcome": "passed"}, "teardown": {"duration": 0.00027129700004024926, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-messages_role_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "messages_role_invalid"}, "setup": {"duration": 0.022483238999939203, "outcome": "passed"}, "call": {"duration": 0.0073873649999995905, "outcome": "passed"}, "teardown": {"duration": 0.0002462100000002465, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_invalid"}, "setup": {"duration": 0.02260937500000182, "outcome": "passed"}, "call": {"duration": 0.10681593599997541, "outcome": "passed"}, "teardown": {"duration": 0.00022457000000031258, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tool_choice_no_tools", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tool_choice_no_tools"}, "setup": {"duration": 0.023524446000010357, "outcome": "passed"}, "call": {"duration": 0.08200232900003357, "outcome": "passed"}, "teardown": {"duration": 0.00031908700009353197, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "lineno": 110, "outcome": "passed", "keywords": ["test_chat_streaming_error_handling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-tools_type_invalid", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "tools_type_invalid"}, "setup": {"duration": 0.02403045200003362, "outcome": "passed"}, "call": {"duration": 0.10543924599994625, "outcome": "passed"}, "teardown": {"duration": 0.00039107999998577725, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 133, "outcome": "skipped", "keywords": ["test_chat_non_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.0318017869999494, "outcome": "passed"}, "call": {"duration": 0.00019770899996274238, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 142, 'Skipped: Skipping test_chat_non_streaming_image for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00016894600003070082, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 133, "outcome": "passed", "keywords": ["test_chat_non_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.022402549000048566, "outcome": "passed"}, "call": {"duration": 2.2238458620000756, "outcome": "passed"}, "teardown": {"duration": 0.0002741329999480513, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 133, "outcome": "passed", "keywords": ["test_chat_non_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.023335573000053955, "outcome": "passed"}, "call": {"duration": 3.4910412369999904, "outcome": "passed"}, "teardown": {"duration": 0.000317483000003449, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 152, "outcome": "skipped", "keywords": ["test_chat_streaming_image[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.022814772000060657, "outcome": "passed"}, "call": {"duration": 0.00016042899994772597, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 161, 'Skipped: Skipping test_chat_streaming_image for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00017679100005807413, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 152, "outcome": "passed", "keywords": ["test_chat_streaming_image[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.021943601999964812, "outcome": "passed"}, "call": {"duration": 1.8935205849999193, "outcome": "passed"}, "teardown": {"duration": 0.00020138699994731724, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 152, "outcome": "passed", "keywords": ["test_chat_streaming_image[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.02235762599991631, "outcome": "passed"}, "call": {"duration": 4.416715701000044, "outcome": "passed"}, "teardown": {"duration": 0.00028265799994642293, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "calendar"}, "setup": {"duration": 0.022428990999969756, "outcome": "passed"}, "call": {"duration": 0.47659577299998546, "outcome": "passed"}, "teardown": {"duration": 0.0002950609999743392, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "math"}, "setup": {"duration": 0.022608506000096895, "outcome": "passed"}, "call": {"duration": 2.7582303990000128, "outcome": "passed"}, "teardown": {"duration": 0.0002620000000206346, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "calendar"}, "setup": {"duration": 0.02227749799999401, "outcome": "passed"}, "call": {"duration": 0.6491791879999482, "outcome": "passed"}, "teardown": {"duration": 0.0003159000000323431, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "math"}, "setup": {"duration": 0.022391212999991694, "outcome": "passed"}, "call": {"duration": 2.4178918929999327, "outcome": "passed"}, "teardown": {"duration": 0.0002800339999566859, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "calendar"}, "setup": {"duration": 0.02336552200006281, "outcome": "passed"}, "call": {"duration": 0.5713325240000131, "outcome": "passed"}, "teardown": {"duration": 0.000261429000033786, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "lineno": 176, "outcome": "passed", "keywords": ["test_chat_non_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "math"}, "setup": {"duration": 0.02352644200004761, "outcome": "passed"}, "call": {"duration": 3.7348512419999906, "outcome": "passed"}, "teardown": {"duration": 0.0002465210000082152, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "calendar"}, "setup": {"duration": 0.032360132999997404, "outcome": "passed"}, "call": {"duration": 0.6030480340000395, "outcome": "passed"}, "teardown": {"duration": 0.0002655760000607188, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "math"}, "setup": {"duration": 0.02237752600001386, "outcome": "passed"}, "call": {"duration": 3.4104041289999714, "outcome": "passed"}, "teardown": {"duration": 0.00022586199997931544, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "calendar"}, "setup": {"duration": 0.022233404999951745, "outcome": "passed"}, "call": {"duration": 0.6750014870000314, "outcome": "passed"}, "teardown": {"duration": 0.0002294789999268687, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "math"}, "setup": {"duration": 0.022234437000065554, "outcome": "passed"}, "call": {"duration": 2.8495487839999214, "outcome": "passed"}, "teardown": {"duration": 0.00023062100001425279, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-calendar", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "calendar"}, "setup": {"duration": 0.022181087999911142, "outcome": "passed"}, "call": {"duration": 0.5464514120000104, "outcome": "passed"}, "teardown": {"duration": 0.0002280960000007326, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "lineno": 199, "outcome": "passed", "keywords": ["test_chat_streaming_structured_output[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-math", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "math"}, "setup": {"duration": 0.02222967900002004, "outcome": "passed"}, "call": {"duration": 2.9783862820000877, "outcome": "passed"}, "teardown": {"duration": 0.00020859999995082035, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 221, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.02175784600001407, "outcome": "passed"}, "call": {"duration": 0.3539575849999892, "outcome": "passed"}, "teardown": {"duration": 0.0002631620000101975, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 221, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.02217127899996285, "outcome": "passed"}, "call": {"duration": 0.4003927260000637, "outcome": "passed"}, "teardown": {"duration": 0.00023894700007076608, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 221, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.02243488100009472, "outcome": "passed"}, "call": {"duration": 0.5933281129999841, "outcome": "passed"}, "teardown": {"duration": 0.00028410100003384287, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 245, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.023472792000006848, "outcome": "passed"}, "call": {"duration": 0.7566981259999466, "outcome": "passed"}, "teardown": {"duration": 0.00028750700005275576, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 245, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.021922644000028413, "outcome": "passed"}, "call": {"duration": 0.3799531690000322, "outcome": "passed"}, "teardown": {"duration": 0.0003171230000589276, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 245, "outcome": "passed", "keywords": ["test_chat_streaming_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.022273428999938005, "outcome": "passed"}, "call": {"duration": 0.8611955730000318, "outcome": "passed"}, "teardown": {"duration": 0.00023423699997238145, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 273, "outcome": "failed", "keywords": ["test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.022599749999926644, "outcome": "passed"}, "call": {"duration": 0.8217204439999932, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 1023, "message": "openai.BadRequestError: Error code: 400 - {'detail': \"Error code: 400 - {'id': 'ntpUCFU-3NKUce-93eea63dccbdf9ed', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}\"}"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 284, "message": ""}, {"path": ".venv/lib/python3.10/site-packages/openai/_utils/_utils.py", "lineno": 279, "message": "in wrapper"}, {"path": ".venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py", "lineno": 914, "message": "in create"}, {"path": ".venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 1242, "message": "in post"}, {"path": ".venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 919, "message": "in request"}, {"path": ".venv/lib/python3.10/site-packages/openai/_base_client.py", "lineno": 1023, "message": "BadRequestError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]>>\nopenai_client = <openai.OpenAI object at 0x7f2df2a14250>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'input': {'messages': [{'content': 'You are a helpful assistant that can use tools to get information.', 'role': 'sys..., 'properties': {...}, 'required': [...], 'type': 'object'}}, 'type': 'function'}]}, 'output': 'get_weather_tool_call'}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_tool_calling\"][\"test_params\"][\"case\"],  # Reusing existing case for now\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_tool_choice_required(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n>       response = openai_client.chat.completions.create(\n            model=model,\n            messages=case[\"input\"][\"messages\"],\n            tools=case[\"input\"][\"tools\"],\n            tool_choice=\"required\",  # Force tool call\n            stream=False,\n        )\n\ntests/verifications/openai_api/test_chat_completion.py:284: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:279: in wrapper\n    return func(*args, **kwargs)\n.venv/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914: in create\n    return self._post(\n.venv/lib/python3.10/site-packages/openai/_base_client.py:1242: in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n.venv/lib/python3.10/site-packages/openai/_base_client.py:919: in request\n    return self._request(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <openai.OpenAI object at 0x7f2df2a14250>\n\n    def _request(\n        self,\n        *,\n        cast_to: Type[ResponseT],\n        options: FinalRequestOptions,\n        retries_taken: int,\n        stream: bool,\n        stream_cls: type[_StreamT] | None,\n    ) -> ResponseT | _StreamT:\n        # create a copy of the options we were given so that if the\n        # options are mutated later & we then retry, the retries are\n        # given the original options\n        input_options = model_copy(options)\n    \n        cast_to = self._maybe_override_cast_to(cast_to, options)\n        options = self._prepare_options(options)\n    \n        remaining_retries = options.get_max_retries(self.max_retries) - retries_taken\n        request = self._build_request(options, retries_taken=retries_taken)\n        self._prepare_request(request)\n    \n        kwargs: HttpxSendArgs = {}\n        if self.custom_auth is not None:\n            kwargs[\"auth\"] = self.custom_auth\n    \n        log.debug(\"Sending HTTP Request: %s %s\", request.method, request.url)\n    \n        try:\n            response = self._client.send(\n                request,\n                stream=stream or self._should_stream_response_body(request=request),\n                **kwargs,\n            )\n        except httpx.TimeoutException as err:\n            log.debug(\"Encountered httpx.TimeoutException\", exc_info=True)\n    \n            if remaining_retries > 0:\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising timeout error\")\n            raise APITimeoutError(request=request) from err\n        except Exception as err:\n            log.debug(\"Encountered Exception\", exc_info=True)\n    \n            if remaining_retries > 0:\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                    response_headers=None,\n                )\n    \n            log.debug(\"Raising connection error\")\n            raise APIConnectionError(request=request) from err\n    \n        log.debug(\n            'HTTP Response: %s %s \"%i %s\" %s',\n            request.method,\n            request.url,\n            response.status_code,\n            response.reason_phrase,\n            response.headers,\n        )\n        log.debug(\"request_id: %s\", response.headers.get(\"x-request-id\"))\n    \n        try:\n            response.raise_for_status()\n        except httpx.HTTPStatusError as err:  # thrown on 4xx and 5xx status code\n            log.debug(\"Encountered httpx.HTTPStatusError\", exc_info=True)\n    \n            if remaining_retries > 0 and self._should_retry(err.response):\n                err.response.close()\n                return self._retry_request(\n                    input_options,\n                    cast_to,\n                    retries_taken=retries_taken,\n                    response_headers=err.response.headers,\n                    stream=stream,\n                    stream_cls=stream_cls,\n                )\n    \n            # If the response is streamed then we need to explicitly read the response\n            # to completion before attempting to access the response text.\n            if not err.response.is_closed:\n                err.response.read()\n    \n            log.debug(\"Re-raising status error\")\n>           raise self._make_status_error_from_response(err.response) from None\nE           openai.BadRequestError: Error code: 400 - {'detail': \"Error code: 400 - {'id': 'ntpUCFU-3NKUce-93eea63dccbdf9ed', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}\"}\n\n.venv/lib/python3.10/site-packages/openai/_base_client.py:1023: BadRequestError"}, "teardown": {"duration": 0.00024184199992305366, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 273, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.02225069700000404, "outcome": "passed"}, "call": {"duration": 0.4054970699999103, "outcome": "passed"}, "teardown": {"duration": 0.00022763599997688289, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 273, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.023318852999977935, "outcome": "passed"}, "call": {"duration": 0.7163137510000297, "outcome": "passed"}, "teardown": {"duration": 0.0003028359999461827, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 297, "outcome": "failed", "keywords": ["test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.02349878000006811, "outcome": "passed"}, "call": {"duration": 0.5719609200000377, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/.venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 72, "message": "openai.APIError: 400: Error code: 400 - {'id': 'ntpUCuh-3NKUce-93eea64b9dedf9ed', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 316, "message": ""}, {"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 682, "message": "in _accumulate_streaming_tool_calls"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 46, "message": "in __iter__"}, {"path": ".venv/lib/python3.10/site-packages/openai/_streaming.py", "lineno": 72, "message": "APIError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_tool_choice_required[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]>>\nopenai_client = <openai.OpenAI object at 0x7f2df2a71030>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'input': {'messages': [{'content': 'You are a helpful assistant that can use tools to get information.', 'role': 'sys..., 'properties': {...}, 'required': [...], 'type': 'object'}}, 'type': 'function'}]}, 'output': 'get_weather_tool_call'}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases[\"test_tool_calling\"][\"test_params\"][\"case\"],  # Reusing existing case for now\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_tool_choice_required(request, openai_client, model, provider, verification_config, case):\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        stream = openai_client.chat.completions.create(\n            model=model,\n            messages=case[\"input\"][\"messages\"],\n            tools=case[\"input\"][\"tools\"],\n            tool_choice=\"required\",  # Force tool call\n            stream=True,\n        )\n    \n>       _, tool_calls_buffer = _accumulate_streaming_tool_calls(stream)\n\ntests/verifications/openai_api/test_chat_completion.py:316: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \ntests/verifications/openai_api/test_chat_completion.py:682: in _accumulate_streaming_tool_calls\n    for chunk in stream:\n.venv/lib/python3.10/site-packages/openai/_streaming.py:46: in __iter__\n    for item in self._iterator:\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <openai.Stream object at 0x7f2df2b977c0>\n\n    def __stream__(self) -> Iterator[_T]:\n        cast_to = cast(Any, self._cast_to)\n        response = self.response\n        process_data = self._client._process_response_data\n        iterator = self._iter_events()\n    \n        for sse in iterator:\n            if sse.data.startswith(\"[DONE]\"):\n                break\n    \n            if sse.event is None or sse.event.startswith(\"response.\") or sse.event.startswith('transcript.'):\n                data = sse.json()\n                if is_mapping(data) and data.get(\"error\"):\n                    message = None\n                    error = data.get(\"error\")\n                    if is_mapping(error):\n                        message = error.get(\"message\")\n                    if not message or not isinstance(message, str):\n                        message = \"An error occurred during streaming\"\n    \n>                   raise APIError(\n                        message=message,\n                        request=self.response.request,\n                        body=data[\"error\"],\n                    )\nE                   openai.APIError: 400: Error code: 400 - {'id': 'ntpUCuh-3NKUce-93eea64b9dedf9ed', 'error': {'message': 'invalid tools grammar: Model supports only tool_choice auto', 'type': 'invalid_request_error', 'param': 'tools', 'code': None}}\n\n.venv/lib/python3.10/site-packages/openai/_streaming.py:72: APIError"}, "teardown": {"duration": 0.00021411000000171043, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 297, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.021809832999906575, "outcome": "passed"}, "call": {"duration": 0.492859185000043, "outcome": "passed"}, "teardown": {"duration": 0.00019715799999175943, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 297, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_required[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.022470386999998482, "outcome": "passed"}, "call": {"duration": 0.6647425580000572, "outcome": "passed"}, "teardown": {"duration": 0.00030442899992522143, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 324, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.022679739000068366, "outcome": "passed"}, "call": {"duration": 1.8164708329999257, "outcome": "passed"}, "teardown": {"duration": 0.00020521399994777312, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 324, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.023453085000028295, "outcome": "passed"}, "call": {"duration": 5.517055897999967, "outcome": "passed"}, "teardown": {"duration": 0.0003136959999210376, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 324, "outcome": "passed", "keywords": ["test_chat_non_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.023281102000055398, "outcome": "passed"}, "call": {"duration": 0.39767485300001226, "outcome": "passed"}, "teardown": {"duration": 0.00033309299999473296, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "case0"}, "setup": {"duration": 0.023128367999902366, "outcome": "passed"}, "call": {"duration": 2.690747809999948, "outcome": "passed"}, "teardown": {"duration": 0.0003170630000113306, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "case0"}, "setup": {"duration": 0.022380209999937506, "outcome": "passed"}, "call": {"duration": 5.907100909000064, "outcome": "passed"}, "teardown": {"duration": 0.0002461999999923137, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "lineno": 347, "outcome": "passed", "keywords": ["test_chat_streaming_tool_choice_none[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-case0", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "case0"}, "setup": {"duration": 0.022078305999912118, "outcome": "passed"}, "call": {"duration": 1.7159313540000767, "outcome": "passed"}, "teardown": {"duration": 0.00033406500006094575, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "lineno": 375, "outcome": "failed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.030148280000048544, "outcome": "passed"}, "call": {"duration": 0.394355934000032, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 434, "message": "AssertionError: Expected 0 tool calls, but got 1\nassert 1 == 0\n +  where 1 = len(([ChatCompletionMessageToolCall(id='call_gwexfzvmjreobmpjc3to3st2', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]))\n +    where [ChatCompletionMessageToolCall(id='call_gwexfzvmjreobmpjc3to3st2', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)] = ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gwexfzvmjreobmpjc3to3st2', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]).tool_calls"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 434, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f2df2b95030>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\"\n        Test cases for multi-turn tool calling.\n        Tool calls are asserted.\n        Tool responses are provided in the test case.\n        Final response is asserted.\n        \"\"\"\n    \n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        # Create a copy of the messages list to avoid modifying the original\n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        # Use deepcopy to prevent modification across runs/parametrization\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        # keep going until either\n        # 1. we have messages to test in multi-turn\n        # 2. no messages but last message is tool response\n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            # do not take new messages if last message is tool response\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                # Ensure new_messages is a list of message objects\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    # If it's a single message object, add it directly\n                    messages.append(new_messages)\n    \n            # --- API Call ---\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=False,\n            )\n    \n            # --- Process Response ---\n            assistant_message = response.choices[0].message\n            messages.append(assistant_message.model_dump(exclude_unset=True))\n    \n            assert assistant_message.role == \"assistant\"\n    \n            # Get the expected result data\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n            # --- Assertions based on expected result ---\n>           assert len(assistant_message.tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(assistant_message.tool_calls or [])}\"\n            )\nE           AssertionError: Expected 0 tool calls, but got 1\nE           assert 1 == 0\nE            +  where 1 = len(([ChatCompletionMessageToolCall(id='call_gwexfzvmjreobmpjc3to3st2', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]))\nE            +    where [ChatCompletionMessageToolCall(id='call_gwexfzvmjreobmpjc3to3st2', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)] = ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gwexfzvmjreobmpjc3to3st2', function=Function(arguments='{\"location\":\"San Francisco, CA\"}', name='get_weather'), type='function', index=0)]).tool_calls\n\ntests/verifications/openai_api/test_chat_completion.py:434: AssertionError"}, "teardown": {"duration": 0.00022654399992916296, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.02228539300006105, "outcome": "passed"}, "call": {"duration": 0.734587796000028, "outcome": "passed"}, "teardown": {"duration": 0.00028968200001600053, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "add_product_tool"}, "setup": {"duration": 0.02372827099998176, "outcome": "passed"}, "call": {"duration": 1.2208458039999641, "outcome": "passed"}, "teardown": {"duration": 0.00024112999994940765, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022395749999986947, "outcome": "passed"}, "call": {"duration": 2.102182909000021, "outcome": "passed"}, "teardown": {"duration": 0.00024304400005803473, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022423460000027262, "outcome": "passed"}, "call": {"duration": 2.3373804209999207, "outcome": "passed"}, "teardown": {"duration": 0.0003142169999819089, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "lineno": 375, "outcome": "failed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.02361170199992557, "outcome": "passed"}, "call": {"duration": 0.3378408330000866, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 462, "message": "AssertionError: Expected one of ['sol'] in content, but got: 'I am unable to fulfill this request as the functions provided are insufficient.'\nassert False\n +  where False = any(<generator object test_chat_non_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f2df298ef80>)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 462, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f2df2caa950>\nmodel = 'together/meta-llama/Llama-4-Scout-17B-16E-Instruct'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\"\n        Test cases for multi-turn tool calling.\n        Tool calls are asserted.\n        Tool responses are provided in the test case.\n        Final response is asserted.\n        \"\"\"\n    \n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        # Create a copy of the messages list to avoid modifying the original\n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        # Use deepcopy to prevent modification across runs/parametrization\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        # keep going until either\n        # 1. we have messages to test in multi-turn\n        # 2. no messages but last message is tool response\n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            # do not take new messages if last message is tool response\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                # Ensure new_messages is a list of message objects\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    # If it's a single message object, add it directly\n                    messages.append(new_messages)\n    \n            # --- API Call ---\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=False,\n            )\n    \n            # --- Process Response ---\n            assistant_message = response.choices[0].message\n            messages.append(assistant_message.model_dump(exclude_unset=True))\n    \n            assert assistant_message.role == \"assistant\"\n    \n            # Get the expected result data\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n            # --- Assertions based on expected result ---\n            assert len(assistant_message.tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(assistant_message.tool_calls or [])}\"\n            )\n    \n            if num_tool_calls > 0:\n                tool_call = assistant_message.tool_calls[0]\n                assert tool_call.function.name == expected[\"tool_name\"], (\n                    f\"Expected tool '{expected['tool_name']}', got '{tool_call.function.name}'\"\n                )\n                # Parse the JSON string arguments before comparing\n                actual_arguments = json.loads(tool_call.function.arguments)\n                assert actual_arguments == expected[\"tool_arguments\"], (\n                    f\"Expected arguments '{expected['tool_arguments']}', got '{actual_arguments}'\"\n                )\n    \n                # Prepare and append the tool response for the next turn\n                tool_response = tool_responses.pop(0)\n                messages.append(\n                    {\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call.id,\n                        \"content\": tool_response[\"response\"],\n                    }\n                )\n            else:\n                assert assistant_message.content is not None, \"Expected content, but none received.\"\n                expected_answers = expected[\"answer\"]  # This is now a list\n                content_lower = assistant_message.content.lower()\n>               assert any(ans.lower() in content_lower for ans in expected_answers), (\n                    f\"Expected one of {expected_answers} in content, but got: '{assistant_message.content}'\"\n                )\nE               AssertionError: Expected one of ['sol'] in content, but got: 'I am unable to fulfill this request as the functions provided are insufficient.'\nE               assert False\nE                +  where False = any(<generator object test_chat_non_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f2df298ef80>)\n\ntests/verifications/openai_api/test_chat_completion.py:462: AssertionError"}, "teardown": {"duration": 0.00020263800001885102, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.02212098600000445, "outcome": "passed"}, "call": {"duration": 0.7788887599999725, "outcome": "passed"}, "teardown": {"duration": 0.00022727400005351228, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "add_product_tool"}, "setup": {"duration": 0.022615108999957556, "outcome": "passed"}, "call": {"duration": 0.8699433990000216, "outcome": "passed"}, "teardown": {"duration": 0.00025723099997776444, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.02441910100003497, "outcome": "passed"}, "call": {"duration": 1.8966398729999128, "outcome": "passed"}, "teardown": {"duration": 0.0002546760000541326, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022239247000015894, "outcome": "passed"}, "call": {"duration": 1.5655203600000505, "outcome": "passed"}, "teardown": {"duration": 0.0002208829999972295, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "lineno": 375, "outcome": "failed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.02253863700002512, "outcome": "passed"}, "call": {"duration": 0.3804744799999753, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 462, "message": "AssertionError: Expected one of ['sol'] in content, but got: '{\"name\": null, \"parameters\": null}'\nassert False\n +  where False = any(<generator object test_chat_non_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f2df2ad0890>)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 462, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f2df2beed40>\nmodel = 'together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_non_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\"\n        Test cases for multi-turn tool calling.\n        Tool calls are asserted.\n        Tool responses are provided in the test case.\n        Final response is asserted.\n        \"\"\"\n    \n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        # Create a copy of the messages list to avoid modifying the original\n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        # Use deepcopy to prevent modification across runs/parametrization\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        # keep going until either\n        # 1. we have messages to test in multi-turn\n        # 2. no messages but last message is tool response\n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            # do not take new messages if last message is tool response\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                # Ensure new_messages is a list of message objects\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    # If it's a single message object, add it directly\n                    messages.append(new_messages)\n    \n            # --- API Call ---\n            response = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=False,\n            )\n    \n            # --- Process Response ---\n            assistant_message = response.choices[0].message\n            messages.append(assistant_message.model_dump(exclude_unset=True))\n    \n            assert assistant_message.role == \"assistant\"\n    \n            # Get the expected result data\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n            # --- Assertions based on expected result ---\n            assert len(assistant_message.tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(assistant_message.tool_calls or [])}\"\n            )\n    \n            if num_tool_calls > 0:\n                tool_call = assistant_message.tool_calls[0]\n                assert tool_call.function.name == expected[\"tool_name\"], (\n                    f\"Expected tool '{expected['tool_name']}', got '{tool_call.function.name}'\"\n                )\n                # Parse the JSON string arguments before comparing\n                actual_arguments = json.loads(tool_call.function.arguments)\n                assert actual_arguments == expected[\"tool_arguments\"], (\n                    f\"Expected arguments '{expected['tool_arguments']}', got '{actual_arguments}'\"\n                )\n    \n                # Prepare and append the tool response for the next turn\n                tool_response = tool_responses.pop(0)\n                messages.append(\n                    {\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call.id,\n                        \"content\": tool_response[\"response\"],\n                    }\n                )\n            else:\n                assert assistant_message.content is not None, \"Expected content, but none received.\"\n                expected_answers = expected[\"answer\"]  # This is now a list\n                content_lower = assistant_message.content.lower()\n>               assert any(ans.lower() in content_lower for ans in expected_answers), (\n                    f\"Expected one of {expected_answers} in content, but got: '{assistant_message.content}'\"\n                )\nE               AssertionError: Expected one of ['sol'] in content, but got: '{\"name\": null, \"parameters\": null}'\nE               assert False\nE                +  where False = any(<generator object test_chat_non_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f2df2ad0890>)\n\ntests/verifications/openai_api/test_chat_completion.py:462: AssertionError"}, "teardown": {"duration": 0.0002533340000354656, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.022282487999973455, "outcome": "passed"}, "call": {"duration": 0.5747456340000099, "outcome": "passed"}, "teardown": {"duration": 0.0003227339999511969, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "add_product_tool"}, "setup": {"duration": 0.02284381599997687, "outcome": "passed"}, "call": {"duration": 0.927503062000028, "outcome": "passed"}, "teardown": {"duration": 0.0002644639999971332, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.02335799800005134, "outcome": "passed"}, "call": {"duration": 1.5903114480000795, "outcome": "passed"}, "teardown": {"duration": 0.0002124469999671419, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "lineno": 375, "outcome": "passed", "keywords": ["test_chat_non_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022199483000008513, "outcome": "passed"}, "call": {"duration": 1.4242644699999119, "outcome": "passed"}, "teardown": {"duration": 0.00019020599995656085, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "lineno": 466, "outcome": "failed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022020528999973976, "outcome": "passed"}, "call": {"duration": 0.38841571900002236, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError: Expected 0 tool calls, but got 1\nassert 1 == 0\n +  where 1 = len(([{'function': {'arguments': '{\"location\":\"San Francisco, CA\"}', 'name': 'get_weather'}, 'id': 'call_illarccx1bs6ugf4sdj0ctad', 'type': 'function'}]))"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f2df2b03bb0>\nmodel = 'together/meta-llama/Llama-3.3-70B-Instruct-Turbo'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\" \"\"\"\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    messages.append(new_messages)\n    \n            # --- API Call (Streaming) ---\n            stream = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n    \n            # --- Process Stream ---\n            accumulated_content, accumulated_tool_calls = _accumulate_streaming_tool_calls(stream)\n    \n            # --- Construct Assistant Message for History ---\n            assistant_message_dict = {\"role\": \"assistant\"}\n            if accumulated_content:\n                assistant_message_dict[\"content\"] = accumulated_content\n            if accumulated_tool_calls:\n                assistant_message_dict[\"tool_calls\"] = accumulated_tool_calls\n    \n            messages.append(assistant_message_dict)\n    \n            # --- Assertions ---\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n>           assert len(accumulated_tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(accumulated_tool_calls or [])}\"\n            )\nE           AssertionError: Expected 0 tool calls, but got 1\nE           assert 1 == 0\nE            +  where 1 = len(([{'function': {'arguments': '{\"location\":\"San Francisco, CA\"}', 'name': 'get_weather'}, 'id': 'call_illarccx1bs6ugf4sdj0ctad', 'type': 'function'}]))\n\ntests/verifications/openai_api/test_chat_completion.py:516: AssertionError"}, "teardown": {"duration": 0.00022686400006932672, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.022091210999974464, "outcome": "passed"}, "call": {"duration": 1.0259963679999373, "outcome": "passed"}, "teardown": {"duration": 0.00020749800000885443, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "add_product_tool"}, "setup": {"duration": 0.022549787000002652, "outcome": "passed"}, "call": {"duration": 1.0133426529999952, "outcome": "passed"}, "teardown": {"duration": 0.00028318900001522707, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022360665000064728, "outcome": "passed"}, "call": {"duration": 2.901783851999994, "outcome": "passed"}, "teardown": {"duration": 0.000210863999996036, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022484687000087433, "outcome": "passed"}, "call": {"duration": 2.210311972999989, "outcome": "passed"}, "teardown": {"duration": 0.00019559499992283236, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "lineno": 466, "outcome": "failed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022024297000029947, "outcome": "passed"}, "call": {"duration": 0.48046519299998636, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 545, "message": "AssertionError: Expected one of ['sol'] in content, but got: 'I am unable to fulfill this request as the functions provided are insufficient.'\nassert False\n +  where False = any(<generator object test_chat_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f2df2ad2e30>)"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 545, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-text_then_weather_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f2df2b95f30>\nmodel = 'together/meta-llama/Llama-4-Scout-17B-16E-Instruct'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'text_then_weather_tool', 'expected': [{'answer': ['sol'], 'num_tool_calls': 0}, {'num_tool_calls': 1, 'to...], 'type': 'object'}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': '70 degrees and foggy'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\" \"\"\"\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    messages.append(new_messages)\n    \n            # --- API Call (Streaming) ---\n            stream = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n    \n            # --- Process Stream ---\n            accumulated_content, accumulated_tool_calls = _accumulate_streaming_tool_calls(stream)\n    \n            # --- Construct Assistant Message for History ---\n            assistant_message_dict = {\"role\": \"assistant\"}\n            if accumulated_content:\n                assistant_message_dict[\"content\"] = accumulated_content\n            if accumulated_tool_calls:\n                assistant_message_dict[\"tool_calls\"] = accumulated_tool_calls\n    \n            messages.append(assistant_message_dict)\n    \n            # --- Assertions ---\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n            assert len(accumulated_tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(accumulated_tool_calls or [])}\"\n            )\n    \n            if num_tool_calls > 0:\n                # Use the first accumulated tool call for assertion\n                tool_call = accumulated_tool_calls[0]\n                assert tool_call[\"function\"][\"name\"] == expected[\"tool_name\"], (\n                    f\"Expected tool '{expected['tool_name']}', got '{tool_call['function']['name']}'\"\n                )\n                # Parse the accumulated arguments string for comparison\n                actual_arguments = json.loads(tool_call[\"function\"][\"arguments\"])\n                assert actual_arguments == expected[\"tool_arguments\"], (\n                    f\"Expected arguments '{expected['tool_arguments']}', got '{actual_arguments}'\"\n                )\n    \n                # Prepare and append the tool response for the next turn\n                tool_response = tool_responses.pop(0)\n                messages.append(\n                    {\n                        \"role\": \"tool\",\n                        \"tool_call_id\": tool_call[\"id\"],\n                        \"content\": tool_response[\"response\"],\n                    }\n                )\n            else:\n                assert accumulated_content is not None and accumulated_content != \"\", \"Expected content, but none received.\"\n                expected_answers = expected[\"answer\"]\n                content_lower = accumulated_content.lower()\n>               assert any(ans.lower() in content_lower for ans in expected_answers), (\n                    f\"Expected one of {expected_answers} in content, but got: '{accumulated_content}'\"\n                )\nE               AssertionError: Expected one of ['sol'] in content, but got: 'I am unable to fulfill this request as the functions provided are insufficient.'\nE               assert False\nE                +  where False = any(<generator object test_chat_streaming_multi_turn_tool_calling.<locals>.<genexpr> at 0x7f2df2ad2e30>)\n\ntests/verifications/openai_api/test_chat_completion.py:545: AssertionError"}, "teardown": {"duration": 0.00021322900011000456, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.021887029000026814, "outcome": "passed"}, "call": {"duration": 1.125573290000034, "outcome": "passed"}, "teardown": {"duration": 0.0002026990000558726, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "lineno": 466, "outcome": "failed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "add_product_tool"}, "setup": {"duration": 0.022332151000000522, "outcome": "passed"}, "call": {"duration": 1.7065250729999661, "outcome": "failed", "crash": {"path": "/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError: Expected 0 tool calls, but got 1\nassert 1 == 0\n +  where 1 = len(([{'function': {'arguments': '{\"inStock\":true,\"name\":\"Widget\",\"price\":19.99,\"tags\":[\"new\",\"sale\"]}', 'name': 'addProduct'}, 'id': 'call_q9vgcie805nexdtlmp74d0gt', 'type': 'function'}]))"}, "traceback": [{"path": "tests/verifications/openai_api/test_chat_completion.py", "lineno": 516, "message": "AssertionError"}], "longrepr": "request = <FixtureRequest for <Function test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-add_product_tool]>>\nopenai_client = <openai.OpenAI object at 0x7f2df293dae0>\nmodel = 'together/meta-llama/Llama-4-Scout-17B-16E-Instruct'\nprovider = 'together-llama-stack'\nverification_config = {'providers': {'cerebras': {'api_key_var': 'CEREBRAS_API_KEY', 'base_url': 'https://api.cerebras.ai/v1', 'model_displa...-versatile', 'meta-llama/llama-4-scout-17b-16e-instruct', 'meta-llama/llama-4-maverick-17b-128e-instruct'], ...}, ...}}\ncase = {'case_id': 'add_product_tool', 'expected': [{'num_tool_calls': 1, 'tool_arguments': {'inStock': True, 'name': 'Widget...}}, 'type': 'function'}]}, 'tool_responses': [{'response': \"{'response': 'Successfully added product with id: 123'}\"}]}\n\n    @pytest.mark.parametrize(\n        \"case\",\n        chat_completion_test_cases.get(\"test_chat_multi_turn_tool_calling\", {}).get(\"test_params\", {}).get(\"case\", []),\n        ids=case_id_generator,\n    )\n    def test_chat_streaming_multi_turn_tool_calling(request, openai_client, model, provider, verification_config, case):\n        \"\"\" \"\"\"\n        test_name_base = get_base_test_name(request)\n        if should_skip_test(verification_config, provider, model, test_name_base):\n            pytest.skip(f\"Skipping {test_name_base} for model {model} on provider {provider} based on config.\")\n    \n        messages = []\n        tools = case[\"input\"][\"tools\"]\n        expected_results = copy.deepcopy(case[\"expected\"])\n        tool_responses = copy.deepcopy(case.get(\"tool_responses\", []))\n        input_messages_turns = copy.deepcopy(case[\"input\"][\"messages\"])\n    \n        while len(input_messages_turns) > 0 or (len(messages) > 0 and messages[-1][\"role\"] == \"tool\"):\n            if len(messages) == 0 or messages[-1][\"role\"] != \"tool\":\n                new_messages = input_messages_turns.pop(0)\n                if isinstance(new_messages, list):\n                    messages.extend(new_messages)\n                else:\n                    messages.append(new_messages)\n    \n            # --- API Call (Streaming) ---\n            stream = openai_client.chat.completions.create(\n                model=model,\n                messages=messages,\n                tools=tools,\n                stream=True,\n            )\n    \n            # --- Process Stream ---\n            accumulated_content, accumulated_tool_calls = _accumulate_streaming_tool_calls(stream)\n    \n            # --- Construct Assistant Message for History ---\n            assistant_message_dict = {\"role\": \"assistant\"}\n            if accumulated_content:\n                assistant_message_dict[\"content\"] = accumulated_content\n            if accumulated_tool_calls:\n                assistant_message_dict[\"tool_calls\"] = accumulated_tool_calls\n    \n            messages.append(assistant_message_dict)\n    \n            # --- Assertions ---\n            expected = expected_results.pop(0)\n            num_tool_calls = expected[\"num_tool_calls\"]\n    \n>           assert len(accumulated_tool_calls or []) == num_tool_calls, (\n                f\"Expected {num_tool_calls} tool calls, but got {len(accumulated_tool_calls or [])}\"\n            )\nE           AssertionError: Expected 0 tool calls, but got 1\nE           assert 1 == 0\nE            +  where 1 = len(([{'function': {'arguments': '{\"inStock\":true,\"name\":\"Widget\",\"price\":19.99,\"tags\":[\"new\",\"sale\"]}', 'name': 'addProduct'}, 'id': 'call_q9vgcie805nexdtlmp74d0gt', 'type': 'function'}]))\n\ntests/verifications/openai_api/test_chat_completion.py:516: AssertionError"}, "teardown": {"duration": 0.0002386060000389989, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.02194641000005504, "outcome": "passed"}, "call": {"duration": 2.3324047940000128, "outcome": "passed"}, "teardown": {"duration": 0.00021085399998810317, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.02216217400007281, "outcome": "passed"}, "call": {"duration": 1.9293508580000207, "outcome": "passed"}, "teardown": {"duration": 0.00023146299997733877, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-text_then_weather_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "text_then_weather_tool"}, "setup": {"duration": 0.022686934000034853, "outcome": "passed"}, "call": {"duration": 3.22239619100003, "outcome": "passed"}, "teardown": {"duration": 0.000225271000090288, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-weather_tool_then_text", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "weather_tool_then_text"}, "setup": {"duration": 0.022131756000021596, "outcome": "passed"}, "call": {"duration": 1.0882494539999925, "outcome": "passed"}, "teardown": {"duration": 0.0002769179999404514, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-add_product_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "add_product_tool"}, "setup": {"duration": 0.026272127000083856, "outcome": "passed"}, "call": {"duration": 1.1229307000000972, "outcome": "passed"}, "teardown": {"duration": 0.00033709000001636014, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-get_then_create_event_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "get_then_create_event_tool"}, "setup": {"duration": 0.022560508000083246, "outcome": "passed"}, "call": {"duration": 1.9557127479999963, "outcome": "passed"}, "teardown": {"duration": 0.0003006420000701837, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "lineno": 466, "outcome": "passed", "keywords": ["test_chat_streaming_multi_turn_tool_calling[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-compare_monthly_expense_tool", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "compare_monthly_expense_tool"}, "setup": {"duration": 0.022877911000023232, "outcome": "passed"}, "call": {"duration": 1.5762783899999704, "outcome": "passed"}, "teardown": {"duration": 0.0002013670000451384, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False]", "lineno": 549, "outcome": "skipped", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "stream=False"}, "setup": {"duration": 0.02288921299998492, "outcome": "passed"}, "call": {"duration": 0.00017113000001245382, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 556, 'Skipped: Skipping test_chat_multi_turn_multiple_images for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00016002899997147324, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True]", "lineno": 549, "outcome": "skipped", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True]", "parametrize", "pytestmark", "together/meta-llama/Llama-3.3-70B-Instruct-Turbo-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo", "case_id": "stream=True"}, "setup": {"duration": 0.022817738999947323, "outcome": "passed"}, "call": {"duration": 0.00012851999997565144, "outcome": "skipped", "longrepr": "('/home/runner/work/llama-stack-tests/llama-stack-tests/tests/verifications/openai_api/test_chat_completion.py', 556, 'Skipped: Skipping test_chat_multi_turn_multiple_images for model together/meta-llama/Llama-3.3-70B-Instruct-Turbo on provider together-llama-stack based on config.')"}, "teardown": {"duration": 0.00015717400003723014, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "stream=False"}, "setup": {"duration": 0.022289492000027167, "outcome": "passed"}, "call": {"duration": 3.4396377729999585, "outcome": "passed"}, "teardown": {"duration": 0.0002235979999340998, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Scout-17B-16E-Instruct-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Scout-17B-16E-Instruct", "case_id": "stream=True"}, "setup": {"duration": 0.026291852999975163, "outcome": "passed"}, "call": {"duration": 3.599111688999983, "outcome": "passed"}, "teardown": {"duration": 0.00022260599996570818, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=False", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "stream=False"}, "setup": {"duration": 0.02284254599999258, "outcome": "passed"}, "call": {"duration": 4.18398377799997, "outcome": "passed"}, "teardown": {"duration": 0.0002867460000288702, "outcome": "passed"}}, {"nodeid": "tests/verifications/openai_api/test_chat_completion.py::test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True]", "lineno": 549, "outcome": "passed", "keywords": ["test_chat_multi_turn_multiple_images[together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True]", "parametrize", "pytestmark", "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8-stream=True", "test_chat_completion.py", "openai_api", "verifications", "tests", "llama-stack-tests", ""], "metadata": {"model": "together/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8", "case_id": "stream=True"}, "setup": {"duration": 0.023464237999974102, "outcome": "passed"}, "call": {"duration": 4.18852799900003, "outcome": "passed"}, "teardown": {"duration": 0.0025348980000217125, "outcome": "passed"}}]}